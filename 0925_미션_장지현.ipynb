{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNkuxQaDMBt5"
   },
   "source": [
    "# **VSC 에서 OpenAI Whisper 사용하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXv9kLODMMLI"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vCdKDfUM9Lw"
   },
   "source": [
    "- 💡 **NOTE**\n",
    "    - 이 과정은 PC Visual Studio Code(이하 VSC)에서 진행합니다.\n",
    "    - 가상환경 생성과 라이브러리 설치는 VSC 터미널에서 진행합니다.\n",
    "    - 아래 내용은 Windows PC 환경을 가정하여 설명되었습니다.    \n",
    "    - 참고 : https://bcuts.tistory.com/192\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfq1gfmZOAnr"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPcm74RoEnQ2"
   },
   "source": [
    "## **Whisper 소개**\n",
    "- Whisper는 OpenAI가 개발한 자동 음성 인식(ASR: Automatic Speech Recognition) 시스템\n",
    "- 2022년 9월 OpenAI에 의해 처음 공개한 오픈 소스 모델\n",
    "- 인터넷에서 수집한 방대한 양의 오디오 데이터로 훈련되어, 다양한 언어와 악센트, 배경 소음 속에서도 매우 뛰어난 정확도를 자랑함\n",
    "- 기존의 음성 인식 모델들이 가진 한계를 극복하고, 음성-텍스트 변환과 언어 번역을 동시에 수행할 수 있도록 설계된 혁신적인 모델\n",
    "- 대규모 약한 지도 학습(Large-Scale Weak Supervision)\"이라는 독특한 방식을 사용\n",
    "    - Whisper는 인터넷에서 수집한 방대한 양의 오디오와 해당 오디오의 전사본으로 학습\n",
    "    - 이 데이터들은 유튜브 영상의 자동 생성 자막처럼 정확도가 완벽하지는 않지만, 양이 엄청나게 많다는 특징을 가짐\n",
    "    - 대량의 \"약한\" 데이터로 학습함으로써, Whisper는 다양한 언어, 배경 소음, 억양 등 현실 세계의 복잡한 음성 환경에 대한 높은 일반화 능력을 갖추게 됨\n",
    "\n",
    "- transcribe : 음성 인식\n",
    "    > model.transcribe(audio, fp16=False)\n",
    "- translate : 번역  \n",
    "    > model.translate(audio, fp16=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYTyJdATEnQ2"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpNGL4AxMa0E"
   },
   "source": [
    "## **설치 순서(Windows)**\n",
    "\n",
    "1. 가상환경 생성 (권장)\n",
    "2. PyTorch 설치\n",
    "3. Whisper 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EttpKVxoMzX5"
   },
   "source": [
    "### **1.가상환경 생성 (권장)**\n",
    "터미널에서 실행한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah_OTgncOYCw"
   },
   "outputs": [],
   "source": [
    "python -m venv whisper-env\n",
    "whisper-env\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7zqLLdUPY-7"
   },
   "source": [
    "- **만약 보안 오류가 발생한 경우(UnauthorizedAccess)**\n",
    "- 해결 방법(영구해결)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDlhyXYaEnQ4"
   },
   "source": [
    "1) VS Code 터미널(파워셸)에서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyJDER2BEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    "Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeMZdkJbEnQ5"
   },
   "source": [
    "2) 새 터미널을 열고 가상환경 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MrccFwvNEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    ".\\whisper-env\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_q3gcpR_EnQ5"
   },
   "source": [
    "3) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OggqmOoEnQ5"
   },
   "outputs": [],
   "source": [
    "# 터미널에서 실행한다.\n",
    "python -c \"import sys; print(sys.executable); print(sys.version)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vt1O4MtgMzff"
   },
   "source": [
    "### **2.PyTorch 설치**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjxo7oBvOD5M"
   },
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzFX1uv9Mznk"
   },
   "source": [
    "### **3.Whisper 설치**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aywVF71vOERd"
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLykieF9EnQ6"
   },
   "source": [
    "### **4.ffmpeg 설치**\n",
    "- 참고 : https://angelplayer.tistory.com/351\n",
    "- https://ffmpeg.org/  \n",
    "- 다운로드 > 윈도우 버튼 >(Windows EXE Files) Windows builds from gyan.dev 선택\n",
    "- ffmpeg-git-full.7z 선택 > 압축풀고 > 폴더 이름을 ffmpeg 으로 변경한다.\n",
    "- ffmpeg 폴더 전체를 C:\\로 이동시키고\n",
    "- 고급 시스템 설정 > 환경변수 > 시스템 변수 > Path에 추가한다. (C:\\ffmpeg\\bin)\n",
    "- 꼭!!! VSC 재시작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxVJoTioEnQ6",
    "outputId": "ff8659bd-1dcc-4b65-fbb8-7ebfbd32b2aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ CWD: c:\\python\\ktcloud_genai\n",
      "▶ Audio Path: C:\\python\\ktcloud_genai\\오디오-슬라이드2.mp3\n",
      "▶ Audio Exists?: True\n",
      "▶ ffmpeg on PATH?: C:\\ffmpeg\\bin\\ffmpeg.EXE\n",
      "▶ ffprobe on PATH?: C:\\ffmpeg\\bin\\ffprobe.EXE\n"
     ]
    }
   ],
   "source": [
    "# 사전 점검 코드\n",
    "from pathlib import Path\n",
    "import shutil, sys\n",
    "\n",
    "audio = Path(r\"./오디오-슬라이드2.mp3\")  # 필요시 절대경로로 바꾸세요\n",
    "print(\"▶ CWD:\", Path.cwd())\n",
    "print(\"▶ Audio Path:\", audio.resolve())\n",
    "print(\"▶ Audio Exists?:\", audio.exists())\n",
    "print(\"▶ ffmpeg on PATH?:\", shutil.which(\"ffmpeg\"))\n",
    "print(\"▶ ffprobe on PATH?:\", shutil.which(\"ffprobe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPadLTQUEnQ6"
   },
   "outputs": [],
   "source": [
    "# - 터미널에서 실행\n",
    "$env:Path = \"C:\\ffmpeg\\bin;\" + $env:Path\n",
    "ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKMISxcdEnQ6",
    "outputId": "290cbdc4-2352-419b-f9f5-2d024df27cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\python\\ktcloud_genai\n",
      "Rel exists?: True\n",
      "Abs exists?: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "print(\"CWD:\", Path.cwd())\n",
    "print(\"Rel exists?:\", Path(\"./오디오-슬라이드2.mp3\").exists())\n",
    "print(\"Abs exists?:\", Path(r\"C:\\python\\ktcloud_genai\\오디오-슬라이드2.mp3\").exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3AetcpfRSd3"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyLeDgtBRTlz"
   },
   "source": [
    "## **Whisper로 음성 파일을 텍스트로 변환하기**\n",
    "\n",
    "1. Whisper 라이브러리 불러오기\n",
    "2. 모델 로드하기\n",
    "3. 음성 파일을 읽어들여 변환\n",
    "4. 결과 출력 또는 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbRJiHnbEnQ7"
   },
   "source": [
    "- 영어 오디오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "2MBQh_HwR5-Z",
    "outputId": "591b45d5-a723-4a7a-969d-33c038e895e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pay attention to me.\n"
     ]
    }
   ],
   "source": [
    "# 1.Whisper 라이브러리 불러오기\n",
    "import whisper\n",
    "\n",
    "# 2.모델 로드하기\n",
    "model = whisper.load_model(\"small\")  # tiny, base, small, medium, large\n",
    "\n",
    "# 3.음성 파일을 읽어들여 변환 .wav, .mp3, .m4a, .webm, .ogg, .flac 등\n",
    "audio = \"아동-영어1.wav\"\n",
    "result = model.transcribe(audio, fp16=False)  # fp16=False 옵션은 CPU 환경에서 필요\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 4.결과 출력 또는 저장\n",
    "with open(\"output_eng.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result[\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxR68TacEnQ7"
   },
   "source": [
    "- 한글 오디오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NiyhvUZbEnQ7",
    "outputId": "08ce66b3-ae9e-44ee-9378-b026bbe82e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 커피의 맛을 이해하기 위해서는 4가지 주요 요소를 살펴보는 것이 중요합니다. 첫째, 삼미는 심맛의 강도를 나타내며 이는 과일이나 로스팅 과정에서 기인합니다. 둘째, 바디감은 커피가 입 안에서 느껴지는 묵직함과 질감을 의미하며 커피의 무게감을 표현합니다.\n",
      "저장 완료: output_kor.txt\n"
     ]
    }
   ],
   "source": [
    "import whisper, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "audio_path = Path(\"/Users/jangjihyeon/kt_cloud_tech_up/ktcloud_genai/오디오-슬라이드2.mp3\") # 절대경로 권장\n",
    "\n",
    "\n",
    "# 1) 필수 전제 확인\n",
    "assert audio_path.exists(), f\"오디오 파일이 없습니다: {audio_path}\"\n",
    "assert shutil.which(\"ffmpeg\"), \"ffmpeg를 찾을 수 없습니다. 설치 후 PATH에 등록하세요.\"\n",
    "assert shutil.which(\"ffprobe\"), \"ffprobe를 찾을 수 없습니다. ffmpeg 설치 시 함께 등록됩니다.\"\n",
    "\n",
    "\n",
    "# 2) 모델 로드 (CPU 사용 시 fp16 비활성화 권장)\n",
    "model = whisper.load_model(\"small\")   # tiny/base/small/medium/large\n",
    "result = model.transcribe(str(audio_path), fp16=False)  # CPU면 fp16=False로 경고 억제\n",
    "print(result[\"text\"])\n",
    "\n",
    "\n",
    "# 3) 저장\n",
    "Path(\"output_kor.txt\").write_text(result[\"text\"], encoding=\"utf-8\")\n",
    "print(\"저장 완료: output_kor.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVHXkFjiEnQ7"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL_d48R8Rjq0"
   },
   "source": [
    "## **실시간 음성 인식**\n",
    "\n",
    "- 참고 : https://bcuts.tistory.com/197\n",
    "\n",
    "- 반복 과정\n",
    "    - 마이크로부터 5초간 음성\n",
    "    - 입력 데이터를 .wav 파일로 저장\n",
    "    - 저장된 파일을 Whisper로 처리\n",
    "    - 텍스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6J67aq1gEnQ7"
   },
   "source": [
    "### 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updating Homebrew...\u001b[0m\n",
      "Adjust how often this is run with `$HOMEBREW_AUTO_UPDATE_SECS` or disable with\n",
      "`$HOMEBREW_NO_AUTO_UPDATE=1`. Hide these hints with `$HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 1 tap (homebrew/cask).\n",
      "\n",
      "You have \u001b[1m18\u001b[0m outdated formulae installed.\n",
      "\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching downloads for: \u001b[32mportaudio\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portaudio/manifests/19.7.0-1\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mportaudio\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/portaudio/blobs/sha256:8ad9f1c1\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring portaudio--19.7.0.arm64_sequoia.bottle.1.tar.gz\u001b[0m\n",
      "🍺  /opt/homebrew/Cellar/portaudio/19.7.0: 34 files, 545.9KB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup portaudio`...\u001b[0m\n",
      "Disable this behaviour by setting `HOMEBREW_NO_INSTALL_CLEANUP=1`.\n",
      "Hide these hints with `HOMEBREW_NO_ENV_HINTS=1` (see `man brew`).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNo outdated dependents to upgrade!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!brew install portaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyaudio: filename=pyaudio-0.2.14-cp313-cp313-macosx_11_0_arm64.whl size=24204 sha256=bc809680c7f6773780668ab0fbed0099657d0a3424527315b2c640ac3cd4b0df\n",
      "  Stored in directory: /Users/jangjihyeon/Library/Caches/pip/wheels/32/45/57/aac45d8ad6f62e05779c15d0e62a09cfb51ff47c3fb1599b36\n",
      "Successfully built pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "Successfully installed pyaudio-0.2.14\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZVhNEJqEnQ7",
    "outputId": "181d8446-9a03-4e71-8e7d-b7198280b22f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/jangjihyeon/miniconda3/lib/python3.13/site-packages (2.3.3)\n",
      "Collecting soundfile\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/jangjihyeon/miniconda3/lib/python3.13/site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/jangjihyeon/miniconda3/lib/python3.13/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[27 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/j4/25jn9cwn74j37fv4yccqxp4w0000gn/T/pip-build-env-u44x6bsj/overlay/lib/python3.13/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: MIT License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-313/pyaudio\n",
      "  \u001b[31m   \u001b[0m copying src/pyaudio/__init__.py -> build/lib.macosx-11.1-arm64-cpython-313/pyaudio\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'pyaudio._portaudio' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-313/src/pyaudio\n",
      "  \u001b[31m   \u001b[0m clang -fno-strict-overflow -Wsign-compare -Wunreachable-code -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /Users/jangjihyeon/miniconda3/include -arch arm64 -fPIC -O2 -isystem /Users/jangjihyeon/miniconda3/include -arch arm64 -DMACOS=1 -I/usr/local/include -I/usr/include -I/opt/homebrew/include -I/Users/jangjihyeon/miniconda3/include/python3.13 -c src/pyaudio/device_api.c -o build/temp.macosx-11.1-arm64-cpython-313/src/pyaudio/device_api.o\n",
      "  \u001b[31m   \u001b[0m src/pyaudio/device_api.c:9:10: fatal error: 'portaudio.h' file not found\n",
      "  \u001b[31m   \u001b[0m     9 | #include \"portaudio.h\"\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
      "\u001b[0mFailed to build pyaudio\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio numpy soundfile # 이렇게 하니까 에러가 뜬다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJXlKdJEnQ8"
   },
   "source": [
    "### 실시간 음성인식 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5FR0RGINEnQ8",
    "outputId": "5f7e0e54-4cbe-4c5c-d668-bd36768d1c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실시간 음성 인식 시작 (Ctrl+C로 종료)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangjihyeon/miniconda3/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 인식된 텍스트:  다른��의\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangjihyeon/miniconda3/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 인식된 텍스트:  한국 super美國與 한국어\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangjihyeon/miniconda3/lib/python3.13/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 인식된 텍스트:  Hi.\n",
      "종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "WAVE_OUTPUT_FILENAME = \"temp.wav\"\n",
    "\n",
    "model = whisper.load_model(\"base\")\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK,\n",
    "                    # 자동 시작 방지, 녹음 직전에 수동으로 start_stream() 호출\n",
    "                    # 추론 중 녹음이 stop되지 않아 버퍼가 계속 쌓여 input overflowed 에러가 떠서 추가했음.\n",
    "                    start = False \n",
    "                    )\n",
    "# 주피터에선 안됨. .py 에서만 가능\n",
    "print(\"실시간 음성 인식 시작 (Ctrl+C로 종료)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = []\n",
    "        #수동으로 시작\n",
    "        stream.start_stream()\n",
    "        # 오디오 수집하는 구간\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK) #청크단위로 데이터 수집\n",
    "            frames.append(data) #청크데이터 frames에 append\n",
    "        stream.stop_stream()\n",
    "        wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb') #바이너리로 쓰기 (temp.wav 녹음파일 생성 혹은 덮어쓰기됨)\n",
    "        \n",
    "        # 녹음 환경 설정 (채널, 샘플폭, 샘플레이트 )\n",
    "        wf.setnchannels(CHANNELS) # 채널 (1)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT)) #샘플폭\n",
    "        wf.setframerate(RATE) #샘플레이트 (16kHz)\n",
    "        # \n",
    "        wf.writeframes(b''.join(frames)) #청크 묶고 파일에 기록\n",
    "        wf.close() # 파일 닫기 (첨부터 with wave.open 쓰는게 더 나은듯?)\n",
    "\n",
    "        result = model.transcribe(WAVE_OUTPUT_FILENAME) # 추론 (speech to text)\n",
    "        # print(type(result)) # dict\n",
    "        print(\"📢 인식된 텍스트:\", result[\"text\"])\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"종료합니다.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mNIgtqgEnQ8"
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
