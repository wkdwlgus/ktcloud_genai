{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLUSIg+h94J54jHWdvPKMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wkdwlgus/ktcloud_genai/blob/main/251016_%EB%B6%84%EB%A5%98%EC%9A%A9_%ED%91%9C%ED%98%84_%EB%AF%B8%EC%84%B8_%ED%8A%9C%EB%8B%9D%ED%95%98%EA%B8%B0_%EC%9E%A5%EC%A7%80%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **분류용 표현 모델 미세 튜닝하기 - 한글**"
      ],
      "metadata": {
        "id": "yp-AQkTjxp64"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMKBaWyz0O4"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets setfit seqeval evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **datasets** :\n",
        "    - https://huggingface.co/datasets\n",
        "    - 허깅페이스 데이터셋\n",
        "- **setfit** :\n",
        "    - https://huggingface.co/docs/setfit/index\n",
        "    - 적은 양의 레이블 데이터만으로 문장 변환(Sentence Transformer) 모델을 효율적으로 파인튜닝하기 위한 프레임워크\n",
        "- **seqeval** : (평가지표)\n",
        "    - https://huggingface.co/spaces/evaluate-metric/seqeval\n",
        "    - 개체명 인식(NER:Named Entity Recognition)과 같은 시퀀스 레이블링(sequence labeling) 태스크의 성능(F1-score, 정밀도 등)을 평가하기 위한 라이브러리"
      ],
      "metadata": {
        "id": "SoXILvQPXfF6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBeVnXxQWy7-"
      },
      "source": [
        "## **데이터**\n",
        "- 모델: `'klue/bert-base'`\n",
        "- 데이터: NSMC(Naver Sentiment Movie Corpus)\n",
        "https://huggingface.co/datasets/Blpeng/nsmc\n",
        "  - train: 150,000개\n",
        "  - test: 50,000개\n",
        "  - Rotten Tomatoes와 유사한 한글 데이터셋"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5phRS_z2U_3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4424d62-8f14-4188-b36b-a855770fc361"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 데이터를 준비하고 분할합니다. 결측값을 제거합니다.\n",
        "dataset = load_dataset(\"Blpeng/nsmc\")\n",
        "train_data = dataset['train'].filter(lambda x: x['document'] is not None).shuffle(seed=42).select(range(8500))\n",
        "test_data = dataset['test'].filter(lambda x: x['document'] is not None).shuffle(seed=42).select(range(1000))\n",
        "\n",
        "# 모델과 토크나이저를 로드합니다.\n",
        "model_id = \"klue/bert-base\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_id, num_labels=2)  # 레이블 개수 2개\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2DT8VlxYBUcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "1_gBUzZ3lZMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af06dec-6a64-400f-ee55-bb1de3172562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'id', 'document', 'label'],\n",
              "    num_rows: 8500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuzlGmB0khFh",
        "outputId": "4b8c5a1a-c3e6-4402-ecd5-36ba82e84878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'id', 'document', 'label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3VD3ZtTaO3q",
        "outputId": "4ddc33ce-d1b5-4016-d458-9462344a2ba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Unnamed: 0': 67616, 'id': 7480534, 'document': '이런 영화는 북쪽이나 틀어라', 'label': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vQBwJpmupLqm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xya5dfmVoR1R"
      },
      "source": [
        "## **지도 분류**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r48vDo8fa33D"
      },
      "source": [
        "데이터를 토큰으로 나눕니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ySNm-a3WCFI"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "   \"\"\"입력 데이터를 토큰으로 나눕니다\"\"\"\n",
        "   return tokenizer(examples[\"document\"], truncation=True)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터를 토큰화합니다.\n",
        "# batched = True -> 여러개 데이터를 배치단위(batch size 만큼 묶어서) 처리 (메모리 문제)\n",
        "# batch_size = 1000 (default)\n",
        "# batched = False -> 데이터를 하나씩 개별 처리 (시간 문제)\n",
        "# => 메모리 시간 trade off\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataCollator: 배치 데이터를 만들고 데이터 증식도 적용할 수 있는 클래스"
      ],
      "metadata": {
        "id": "-02zH6-4jvro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# DataCollactor가 왜 필요할까?\n",
        "# 토큰화된 데이터\n",
        "sample1 = {\"input_ids\": [101, 146, 1567, 102]}                    # 길이 4\n",
        "sample2 = {\"input_ids\": [101, 1188, 1110, 2213, 999, 102]}        # 길이 6\n",
        "sample3 = {\"input_ids\": [101, 2026, 2523, 106, 102]}              # 길이 5\n",
        "\n",
        "# 배치로 묶으려면?\n",
        "batch = [sample1, sample2, sample3]\n",
        "\n",
        "# ❌ 텐서로 변환 불가능! (길이가 달라서)\n",
        "tensor = torch.tensor([\n",
        "    [101, 146, 1567, 102],           # 4개\n",
        "    [101, 1188, 1110, 2213, 999, 102],  # 6개  ← 에러!\n",
        "    [101, 2026, 2523, 106, 102]      # 5개\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "TKeVselrMqWj",
        "outputId": "1816655a-dc52-477a-cd02-85dd0cae2d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "expected sequence of length 4 at dim 1 (got 6)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-176925255.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# ❌ 텐서로 변환 불가능! (길이가 달라서)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m tensor = torch.tensor([\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m146\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1567\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m102\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# 4개\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1188\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1110\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2213\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m102\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 6개  ← 에러!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 4 at dim 1 (got 6)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG1WwM15PrRT"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# 배치에서 가장 긴 시퀀스에 맞춰 패딩합니다.\n",
        "# data_collator(samples) 혹은 trainer.train() 시점에 패딩이 추가됨\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ1NM1gjbMD7"
      },
      "source": [
        "측정 지표를 정의합니다. (confusion matrix)\n",
        "\n",
        "- **F1-score**\n",
        "    - **정밀도(Precision)와 재현율(Recall)의 조화평균**\n",
        "    - 데이터 불균형(Imbalanced Data)이 심할 때 모델의 성능을 정확하게 평가하기 위해 주로 사용\n",
        "    - 정밀도(Precision)와 재현율(Recall)을 모두 중요하게 고려해야 할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "정밀도 (Precision) = TP / (TP + FP)\n",
        "- 긍정이라고 예측한 것 중 실제 긍정 비율\n",
        "\n",
        "재현율 (Recall) = TP / (TP + FN)\n",
        "- 실제 긍정 중 긍정으로 예측한 비율\n",
        "\n",
        "F1-Score = 2 × (Precision × Recall) / (Precision + Recall)\n",
        "- 정밀도와 재현율의 조화평균\n",
        "- 불균형 데이터 -> **실제: 스팸 10개, 정상 90개**\n",
        "\n",
        "- 모델이 모두 \"정상\"이라고 예측 -> **예측: 전부 정상**\n",
        "\n",
        "- 정확도 = 90/100 = 90%  ← 높아 보이지만...\n",
        "스팸을 하나도 못 잡음! ❌\n",
        "- 정밀도 = 0 / (0 + 0) = 계산 불가\n",
        "- 재현율 = 0 / (0 + 10) = 0%\n",
        "- F1-Score = 0%  ← 실제 성능 반영! ✅"
      ],
      "metadata": {
        "id": "Ca1WpDx-QQHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y724gUYyWIvq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"F1 점수를 계산합니다\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    load_f1 = evaluate.load(\"f1\")\n",
        "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
        "    return {\"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAm-sAl9bOPC"
      },
      "source": [
        "모델을 훈련합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dho6VcG9WK5u"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# 훈련 매개변수\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,              # 0.00002\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# 훈련 과정을 수행할 Trainer 객체\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   processing_class=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOzl0WnSbVnY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "09a93473-2f85-44a0-e3d8-98f3ce46acda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.377500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=532, training_loss=0.371744121823992, metrics={'train_runtime': 29.9852, 'train_samples_per_second': 283.473, 'train_steps_per_second': 17.742, 'total_flos': 275847274883520.0, 'train_loss': 0.371744121823992, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkBUVlUYbUnn"
      },
      "source": [
        "모델을 평가합니다.\n",
        "eval_f1 으로 평가 (1에 가까울수록 정확도 높은거(성능 높은거))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCI9uYDObWU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "25d3a101-b25b-44d6-81fb-67e847710a47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:09]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.2849462330341339,\n",
              " 'eval_f1': 0.8830897703549061,\n",
              " 'eval_runtime': 1.4523,\n",
              " 'eval_samples_per_second': 688.545,\n",
              " 'eval_steps_per_second': 43.378,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainer.evaluate()\n",
        "# 0.883"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5gefwxOBllA"
      },
      "source": [
        "### **Layer Freezing**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저를 로드합니다.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TPNmmvct0CQ",
        "outputId": "d64dbd31-f90e-42ea-c0e1-5da951453e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI8vf_mnBniu",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6307ab-4e78-4191-bfc1-e16f657423d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: bert.embeddings.word_embeddings.weight\n",
            "1: bert.embeddings.position_embeddings.weight\n",
            "2: bert.embeddings.token_type_embeddings.weight\n",
            "3: bert.embeddings.LayerNorm.weight\n",
            "4: bert.embeddings.LayerNorm.bias\n",
            "5: bert.encoder.layer.0.attention.self.query.weight\n",
            "6: bert.encoder.layer.0.attention.self.query.bias\n",
            "7: bert.encoder.layer.0.attention.self.key.weight\n",
            "8: bert.encoder.layer.0.attention.self.key.bias\n",
            "9: bert.encoder.layer.0.attention.self.value.weight\n",
            "10: bert.encoder.layer.0.attention.self.value.bias\n",
            "11: bert.encoder.layer.0.attention.output.dense.weight\n",
            "12: bert.encoder.layer.0.attention.output.dense.bias\n",
            "13: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "14: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "15: bert.encoder.layer.0.intermediate.dense.weight\n",
            "16: bert.encoder.layer.0.intermediate.dense.bias\n",
            "17: bert.encoder.layer.0.output.dense.weight\n",
            "18: bert.encoder.layer.0.output.dense.bias\n",
            "19: bert.encoder.layer.0.output.LayerNorm.weight\n",
            "20: bert.encoder.layer.0.output.LayerNorm.bias\n",
            "21: bert.encoder.layer.1.attention.self.query.weight\n",
            "22: bert.encoder.layer.1.attention.self.query.bias\n",
            "23: bert.encoder.layer.1.attention.self.key.weight\n",
            "24: bert.encoder.layer.1.attention.self.key.bias\n",
            "25: bert.encoder.layer.1.attention.self.value.weight\n",
            "26: bert.encoder.layer.1.attention.self.value.bias\n",
            "27: bert.encoder.layer.1.attention.output.dense.weight\n",
            "28: bert.encoder.layer.1.attention.output.dense.bias\n",
            "29: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "30: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "31: bert.encoder.layer.1.intermediate.dense.weight\n",
            "32: bert.encoder.layer.1.intermediate.dense.bias\n",
            "33: bert.encoder.layer.1.output.dense.weight\n",
            "34: bert.encoder.layer.1.output.dense.bias\n",
            "35: bert.encoder.layer.1.output.LayerNorm.weight\n",
            "36: bert.encoder.layer.1.output.LayerNorm.bias\n",
            "37: bert.encoder.layer.2.attention.self.query.weight\n",
            "38: bert.encoder.layer.2.attention.self.query.bias\n",
            "39: bert.encoder.layer.2.attention.self.key.weight\n",
            "40: bert.encoder.layer.2.attention.self.key.bias\n",
            "41: bert.encoder.layer.2.attention.self.value.weight\n",
            "42: bert.encoder.layer.2.attention.self.value.bias\n",
            "43: bert.encoder.layer.2.attention.output.dense.weight\n",
            "44: bert.encoder.layer.2.attention.output.dense.bias\n",
            "45: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "46: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "47: bert.encoder.layer.2.intermediate.dense.weight\n",
            "48: bert.encoder.layer.2.intermediate.dense.bias\n",
            "49: bert.encoder.layer.2.output.dense.weight\n",
            "50: bert.encoder.layer.2.output.dense.bias\n",
            "51: bert.encoder.layer.2.output.LayerNorm.weight\n",
            "52: bert.encoder.layer.2.output.LayerNorm.bias\n",
            "53: bert.encoder.layer.3.attention.self.query.weight\n",
            "54: bert.encoder.layer.3.attention.self.query.bias\n",
            "55: bert.encoder.layer.3.attention.self.key.weight\n",
            "56: bert.encoder.layer.3.attention.self.key.bias\n",
            "57: bert.encoder.layer.3.attention.self.value.weight\n",
            "58: bert.encoder.layer.3.attention.self.value.bias\n",
            "59: bert.encoder.layer.3.attention.output.dense.weight\n",
            "60: bert.encoder.layer.3.attention.output.dense.bias\n",
            "61: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "62: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "63: bert.encoder.layer.3.intermediate.dense.weight\n",
            "64: bert.encoder.layer.3.intermediate.dense.bias\n",
            "65: bert.encoder.layer.3.output.dense.weight\n",
            "66: bert.encoder.layer.3.output.dense.bias\n",
            "67: bert.encoder.layer.3.output.LayerNorm.weight\n",
            "68: bert.encoder.layer.3.output.LayerNorm.bias\n",
            "69: bert.encoder.layer.4.attention.self.query.weight\n",
            "70: bert.encoder.layer.4.attention.self.query.bias\n",
            "71: bert.encoder.layer.4.attention.self.key.weight\n",
            "72: bert.encoder.layer.4.attention.self.key.bias\n",
            "73: bert.encoder.layer.4.attention.self.value.weight\n",
            "74: bert.encoder.layer.4.attention.self.value.bias\n",
            "75: bert.encoder.layer.4.attention.output.dense.weight\n",
            "76: bert.encoder.layer.4.attention.output.dense.bias\n",
            "77: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "78: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "79: bert.encoder.layer.4.intermediate.dense.weight\n",
            "80: bert.encoder.layer.4.intermediate.dense.bias\n",
            "81: bert.encoder.layer.4.output.dense.weight\n",
            "82: bert.encoder.layer.4.output.dense.bias\n",
            "83: bert.encoder.layer.4.output.LayerNorm.weight\n",
            "84: bert.encoder.layer.4.output.LayerNorm.bias\n",
            "85: bert.encoder.layer.5.attention.self.query.weight\n",
            "86: bert.encoder.layer.5.attention.self.query.bias\n",
            "87: bert.encoder.layer.5.attention.self.key.weight\n",
            "88: bert.encoder.layer.5.attention.self.key.bias\n",
            "89: bert.encoder.layer.5.attention.self.value.weight\n",
            "90: bert.encoder.layer.5.attention.self.value.bias\n",
            "91: bert.encoder.layer.5.attention.output.dense.weight\n",
            "92: bert.encoder.layer.5.attention.output.dense.bias\n",
            "93: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "94: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "95: bert.encoder.layer.5.intermediate.dense.weight\n",
            "96: bert.encoder.layer.5.intermediate.dense.bias\n",
            "97: bert.encoder.layer.5.output.dense.weight\n",
            "98: bert.encoder.layer.5.output.dense.bias\n",
            "99: bert.encoder.layer.5.output.LayerNorm.weight\n",
            "100: bert.encoder.layer.5.output.LayerNorm.bias\n",
            "101: bert.encoder.layer.6.attention.self.query.weight\n",
            "102: bert.encoder.layer.6.attention.self.query.bias\n",
            "103: bert.encoder.layer.6.attention.self.key.weight\n",
            "104: bert.encoder.layer.6.attention.self.key.bias\n",
            "105: bert.encoder.layer.6.attention.self.value.weight\n",
            "106: bert.encoder.layer.6.attention.self.value.bias\n",
            "107: bert.encoder.layer.6.attention.output.dense.weight\n",
            "108: bert.encoder.layer.6.attention.output.dense.bias\n",
            "109: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "110: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "111: bert.encoder.layer.6.intermediate.dense.weight\n",
            "112: bert.encoder.layer.6.intermediate.dense.bias\n",
            "113: bert.encoder.layer.6.output.dense.weight\n",
            "114: bert.encoder.layer.6.output.dense.bias\n",
            "115: bert.encoder.layer.6.output.LayerNorm.weight\n",
            "116: bert.encoder.layer.6.output.LayerNorm.bias\n",
            "117: bert.encoder.layer.7.attention.self.query.weight\n",
            "118: bert.encoder.layer.7.attention.self.query.bias\n",
            "119: bert.encoder.layer.7.attention.self.key.weight\n",
            "120: bert.encoder.layer.7.attention.self.key.bias\n",
            "121: bert.encoder.layer.7.attention.self.value.weight\n",
            "122: bert.encoder.layer.7.attention.self.value.bias\n",
            "123: bert.encoder.layer.7.attention.output.dense.weight\n",
            "124: bert.encoder.layer.7.attention.output.dense.bias\n",
            "125: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "126: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "127: bert.encoder.layer.7.intermediate.dense.weight\n",
            "128: bert.encoder.layer.7.intermediate.dense.bias\n",
            "129: bert.encoder.layer.7.output.dense.weight\n",
            "130: bert.encoder.layer.7.output.dense.bias\n",
            "131: bert.encoder.layer.7.output.LayerNorm.weight\n",
            "132: bert.encoder.layer.7.output.LayerNorm.bias\n",
            "133: bert.encoder.layer.8.attention.self.query.weight\n",
            "134: bert.encoder.layer.8.attention.self.query.bias\n",
            "135: bert.encoder.layer.8.attention.self.key.weight\n",
            "136: bert.encoder.layer.8.attention.self.key.bias\n",
            "137: bert.encoder.layer.8.attention.self.value.weight\n",
            "138: bert.encoder.layer.8.attention.self.value.bias\n",
            "139: bert.encoder.layer.8.attention.output.dense.weight\n",
            "140: bert.encoder.layer.8.attention.output.dense.bias\n",
            "141: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "142: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "143: bert.encoder.layer.8.intermediate.dense.weight\n",
            "144: bert.encoder.layer.8.intermediate.dense.bias\n",
            "145: bert.encoder.layer.8.output.dense.weight\n",
            "146: bert.encoder.layer.8.output.dense.bias\n",
            "147: bert.encoder.layer.8.output.LayerNorm.weight\n",
            "148: bert.encoder.layer.8.output.LayerNorm.bias\n",
            "149: bert.encoder.layer.9.attention.self.query.weight\n",
            "150: bert.encoder.layer.9.attention.self.query.bias\n",
            "151: bert.encoder.layer.9.attention.self.key.weight\n",
            "152: bert.encoder.layer.9.attention.self.key.bias\n",
            "153: bert.encoder.layer.9.attention.self.value.weight\n",
            "154: bert.encoder.layer.9.attention.self.value.bias\n",
            "155: bert.encoder.layer.9.attention.output.dense.weight\n",
            "156: bert.encoder.layer.9.attention.output.dense.bias\n",
            "157: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "158: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "159: bert.encoder.layer.9.intermediate.dense.weight\n",
            "160: bert.encoder.layer.9.intermediate.dense.bias\n",
            "161: bert.encoder.layer.9.output.dense.weight\n",
            "162: bert.encoder.layer.9.output.dense.bias\n",
            "163: bert.encoder.layer.9.output.LayerNorm.weight\n",
            "164: bert.encoder.layer.9.output.LayerNorm.bias\n",
            "165: bert.encoder.layer.10.attention.self.query.weight\n",
            "166: bert.encoder.layer.10.attention.self.query.bias\n",
            "167: bert.encoder.layer.10.attention.self.key.weight\n",
            "168: bert.encoder.layer.10.attention.self.key.bias\n",
            "169: bert.encoder.layer.10.attention.self.value.weight\n",
            "170: bert.encoder.layer.10.attention.self.value.bias\n",
            "171: bert.encoder.layer.10.attention.output.dense.weight\n",
            "172: bert.encoder.layer.10.attention.output.dense.bias\n",
            "173: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "174: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "175: bert.encoder.layer.10.intermediate.dense.weight\n",
            "176: bert.encoder.layer.10.intermediate.dense.bias\n",
            "177: bert.encoder.layer.10.output.dense.weight\n",
            "178: bert.encoder.layer.10.output.dense.bias\n",
            "179: bert.encoder.layer.10.output.LayerNorm.weight\n",
            "180: bert.encoder.layer.10.output.LayerNorm.bias\n",
            "181: bert.encoder.layer.11.attention.self.query.weight\n",
            "182: bert.encoder.layer.11.attention.self.query.bias\n",
            "183: bert.encoder.layer.11.attention.self.key.weight\n",
            "184: bert.encoder.layer.11.attention.self.key.bias\n",
            "185: bert.encoder.layer.11.attention.self.value.weight\n",
            "186: bert.encoder.layer.11.attention.self.value.bias\n",
            "187: bert.encoder.layer.11.attention.output.dense.weight\n",
            "188: bert.encoder.layer.11.attention.output.dense.bias\n",
            "189: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "190: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "191: bert.encoder.layer.11.intermediate.dense.weight\n",
            "192: bert.encoder.layer.11.intermediate.dense.bias\n",
            "193: bert.encoder.layer.11.output.dense.weight\n",
            "194: bert.encoder.layer.11.output.dense.bias\n",
            "195: bert.encoder.layer.11.output.LayerNorm.weight\n",
            "196: bert.encoder.layer.11.output.LayerNorm.bias\n",
            "197: bert.pooler.dense.weight\n",
            "198: bert.pooler.dense.bias\n",
            "199: classifier.weight\n",
            "200: classifier.bias\n"
          ]
        }
      ],
      "source": [
        "# 층 이름을 출력합니다.\n",
        "i = 0\n",
        "for name, params in model.named_parameters():\n",
        "    print(f'{i}:', name)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "classifier(분류 헤드) 를 제외한 모든 층 동결하기"
      ],
      "metadata": {
        "id": "ed27iVKKpmnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnpGOry_Bm36"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "\n",
        "     # 분류 헤드는 동결하지 않습니다.\n",
        "     if name.startswith(\"classifier\"):\n",
        "\n",
        "        # 역전파시 그래디언트(dloss/dweight) 계산 여부 결정\n",
        "        # 이 파라미터는 훈련 중에 업데이트되어야 한다는 의미\n",
        "        param.requires_grad = True\n",
        "\n",
        "\n",
        "     # 그외 모든 층을 동결합니다.\n",
        "     else:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf_wYzpMB4uX",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34a8f02-6931-4072-dc78-7984d6d2b245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: bert.embeddings.word_embeddings.weight ----- False --- torch.Size([32000, 768])\n",
            "1: bert.embeddings.position_embeddings.weight ----- False --- torch.Size([512, 768])\n",
            "2: bert.embeddings.token_type_embeddings.weight ----- False --- torch.Size([2, 768])\n",
            "3: bert.embeddings.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "4: bert.embeddings.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "5: bert.encoder.layer.0.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "6: bert.encoder.layer.0.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "7: bert.encoder.layer.0.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "8: bert.encoder.layer.0.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "9: bert.encoder.layer.0.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "10: bert.encoder.layer.0.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "11: bert.encoder.layer.0.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "12: bert.encoder.layer.0.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "13: bert.encoder.layer.0.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "14: bert.encoder.layer.0.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "15: bert.encoder.layer.0.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "16: bert.encoder.layer.0.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "17: bert.encoder.layer.0.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "18: bert.encoder.layer.0.output.dense.bias ----- False --- torch.Size([768])\n",
            "19: bert.encoder.layer.0.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "20: bert.encoder.layer.0.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "21: bert.encoder.layer.1.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "22: bert.encoder.layer.1.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "23: bert.encoder.layer.1.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "24: bert.encoder.layer.1.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "25: bert.encoder.layer.1.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "26: bert.encoder.layer.1.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "27: bert.encoder.layer.1.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "28: bert.encoder.layer.1.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "29: bert.encoder.layer.1.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "30: bert.encoder.layer.1.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "31: bert.encoder.layer.1.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "32: bert.encoder.layer.1.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "33: bert.encoder.layer.1.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "34: bert.encoder.layer.1.output.dense.bias ----- False --- torch.Size([768])\n",
            "35: bert.encoder.layer.1.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "36: bert.encoder.layer.1.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "37: bert.encoder.layer.2.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "38: bert.encoder.layer.2.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "39: bert.encoder.layer.2.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "40: bert.encoder.layer.2.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "41: bert.encoder.layer.2.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "42: bert.encoder.layer.2.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "43: bert.encoder.layer.2.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "44: bert.encoder.layer.2.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "45: bert.encoder.layer.2.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "46: bert.encoder.layer.2.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "47: bert.encoder.layer.2.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "48: bert.encoder.layer.2.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "49: bert.encoder.layer.2.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "50: bert.encoder.layer.2.output.dense.bias ----- False --- torch.Size([768])\n",
            "51: bert.encoder.layer.2.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "52: bert.encoder.layer.2.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "53: bert.encoder.layer.3.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "54: bert.encoder.layer.3.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "55: bert.encoder.layer.3.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "56: bert.encoder.layer.3.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "57: bert.encoder.layer.3.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "58: bert.encoder.layer.3.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "59: bert.encoder.layer.3.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "60: bert.encoder.layer.3.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "61: bert.encoder.layer.3.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "62: bert.encoder.layer.3.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "63: bert.encoder.layer.3.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "64: bert.encoder.layer.3.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "65: bert.encoder.layer.3.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "66: bert.encoder.layer.3.output.dense.bias ----- False --- torch.Size([768])\n",
            "67: bert.encoder.layer.3.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "68: bert.encoder.layer.3.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "69: bert.encoder.layer.4.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "70: bert.encoder.layer.4.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "71: bert.encoder.layer.4.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "72: bert.encoder.layer.4.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "73: bert.encoder.layer.4.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "74: bert.encoder.layer.4.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "75: bert.encoder.layer.4.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "76: bert.encoder.layer.4.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "77: bert.encoder.layer.4.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "78: bert.encoder.layer.4.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "79: bert.encoder.layer.4.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "80: bert.encoder.layer.4.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "81: bert.encoder.layer.4.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "82: bert.encoder.layer.4.output.dense.bias ----- False --- torch.Size([768])\n",
            "83: bert.encoder.layer.4.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "84: bert.encoder.layer.4.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "85: bert.encoder.layer.5.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "86: bert.encoder.layer.5.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "87: bert.encoder.layer.5.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "88: bert.encoder.layer.5.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "89: bert.encoder.layer.5.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "90: bert.encoder.layer.5.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "91: bert.encoder.layer.5.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "92: bert.encoder.layer.5.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "93: bert.encoder.layer.5.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "94: bert.encoder.layer.5.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "95: bert.encoder.layer.5.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "96: bert.encoder.layer.5.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "97: bert.encoder.layer.5.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "98: bert.encoder.layer.5.output.dense.bias ----- False --- torch.Size([768])\n",
            "99: bert.encoder.layer.5.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "100: bert.encoder.layer.5.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "101: bert.encoder.layer.6.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "102: bert.encoder.layer.6.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "103: bert.encoder.layer.6.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "104: bert.encoder.layer.6.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "105: bert.encoder.layer.6.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "106: bert.encoder.layer.6.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "107: bert.encoder.layer.6.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "108: bert.encoder.layer.6.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "109: bert.encoder.layer.6.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "110: bert.encoder.layer.6.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "111: bert.encoder.layer.6.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "112: bert.encoder.layer.6.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "113: bert.encoder.layer.6.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "114: bert.encoder.layer.6.output.dense.bias ----- False --- torch.Size([768])\n",
            "115: bert.encoder.layer.6.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "116: bert.encoder.layer.6.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "117: bert.encoder.layer.7.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "118: bert.encoder.layer.7.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "119: bert.encoder.layer.7.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "120: bert.encoder.layer.7.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "121: bert.encoder.layer.7.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "122: bert.encoder.layer.7.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "123: bert.encoder.layer.7.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "124: bert.encoder.layer.7.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "125: bert.encoder.layer.7.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "126: bert.encoder.layer.7.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "127: bert.encoder.layer.7.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "128: bert.encoder.layer.7.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "129: bert.encoder.layer.7.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "130: bert.encoder.layer.7.output.dense.bias ----- False --- torch.Size([768])\n",
            "131: bert.encoder.layer.7.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "132: bert.encoder.layer.7.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "133: bert.encoder.layer.8.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "134: bert.encoder.layer.8.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "135: bert.encoder.layer.8.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "136: bert.encoder.layer.8.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "137: bert.encoder.layer.8.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "138: bert.encoder.layer.8.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "139: bert.encoder.layer.8.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "140: bert.encoder.layer.8.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "141: bert.encoder.layer.8.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "142: bert.encoder.layer.8.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "143: bert.encoder.layer.8.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "144: bert.encoder.layer.8.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "145: bert.encoder.layer.8.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "146: bert.encoder.layer.8.output.dense.bias ----- False --- torch.Size([768])\n",
            "147: bert.encoder.layer.8.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "148: bert.encoder.layer.8.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "149: bert.encoder.layer.9.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "150: bert.encoder.layer.9.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "151: bert.encoder.layer.9.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "152: bert.encoder.layer.9.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "153: bert.encoder.layer.9.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "154: bert.encoder.layer.9.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "155: bert.encoder.layer.9.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "156: bert.encoder.layer.9.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "157: bert.encoder.layer.9.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "158: bert.encoder.layer.9.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "159: bert.encoder.layer.9.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "160: bert.encoder.layer.9.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "161: bert.encoder.layer.9.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "162: bert.encoder.layer.9.output.dense.bias ----- False --- torch.Size([768])\n",
            "163: bert.encoder.layer.9.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "164: bert.encoder.layer.9.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "165: bert.encoder.layer.10.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "166: bert.encoder.layer.10.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "167: bert.encoder.layer.10.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "168: bert.encoder.layer.10.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "169: bert.encoder.layer.10.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "170: bert.encoder.layer.10.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "171: bert.encoder.layer.10.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "172: bert.encoder.layer.10.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "173: bert.encoder.layer.10.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "174: bert.encoder.layer.10.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "175: bert.encoder.layer.10.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "176: bert.encoder.layer.10.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "177: bert.encoder.layer.10.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "178: bert.encoder.layer.10.output.dense.bias ----- False --- torch.Size([768])\n",
            "179: bert.encoder.layer.10.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "180: bert.encoder.layer.10.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "181: bert.encoder.layer.11.attention.self.query.weight ----- False --- torch.Size([768, 768])\n",
            "182: bert.encoder.layer.11.attention.self.query.bias ----- False --- torch.Size([768])\n",
            "183: bert.encoder.layer.11.attention.self.key.weight ----- False --- torch.Size([768, 768])\n",
            "184: bert.encoder.layer.11.attention.self.key.bias ----- False --- torch.Size([768])\n",
            "185: bert.encoder.layer.11.attention.self.value.weight ----- False --- torch.Size([768, 768])\n",
            "186: bert.encoder.layer.11.attention.self.value.bias ----- False --- torch.Size([768])\n",
            "187: bert.encoder.layer.11.attention.output.dense.weight ----- False --- torch.Size([768, 768])\n",
            "188: bert.encoder.layer.11.attention.output.dense.bias ----- False --- torch.Size([768])\n",
            "189: bert.encoder.layer.11.attention.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "190: bert.encoder.layer.11.attention.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "191: bert.encoder.layer.11.intermediate.dense.weight ----- False --- torch.Size([3072, 768])\n",
            "192: bert.encoder.layer.11.intermediate.dense.bias ----- False --- torch.Size([3072])\n",
            "193: bert.encoder.layer.11.output.dense.weight ----- False --- torch.Size([768, 3072])\n",
            "194: bert.encoder.layer.11.output.dense.bias ----- False --- torch.Size([768])\n",
            "195: bert.encoder.layer.11.output.LayerNorm.weight ----- False --- torch.Size([768])\n",
            "196: bert.encoder.layer.11.output.LayerNorm.bias ----- False --- torch.Size([768])\n",
            "197: bert.pooler.dense.weight ----- False --- torch.Size([768, 768])\n",
            "198: bert.pooler.dense.bias ----- False --- torch.Size([768])\n",
            "199: classifier.weight ----- True --- torch.Size([2, 768])\n",
            "200: classifier.bias ----- True --- torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "# 모델이 올바르게 업데이트되었는지 확인합니다.\n",
        "for index, (name, param) in enumerate(model.named_parameters()):\n",
        "\n",
        "  print(f\"{index}: {name} ----- {param.requires_grad} --- {param.shape}\")\n",
        "\n",
        "# 동결 안한 층(분류 헤드)\n",
        "#  - classifier.weight\n",
        "#  - classifier.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVi36FJSG4ue",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "a182f369-4a5b-4770-b4fd-6a7d3c788ed5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:12, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.680400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=532, training_loss=0.6790811997607238, metrics={'train_runtime': 12.2025, 'train_samples_per_second': 696.576, 'train_steps_per_second': 43.597, 'total_flos': 275847274883520.0, 'train_loss': 0.6790811997607238, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# 훈련 과정을 실행할 Trainer 객체를 만듭니다.\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   processing_class=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCPpixB1HCsI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1f5a61aa-bdf9-4e0d-89e8-310909ef9cdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6491261124610901,\n",
              " 'eval_f1': 0.646,\n",
              " 'eval_runtime': 1.4295,\n",
              " 'eval_samples_per_second': 699.526,\n",
              " 'eval_steps_per_second': 44.07,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer.evaluate()\n",
        "# 0.646"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw729mLhIQL6"
      },
      "source": [
        "### **partial fine-tuning: 10개의 인코더 블록 동결하기**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델과 토크나이저를 로드합니다.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohBH8crKuCrw",
        "outputId": "4d02ee25-075a-4801-860b-320f3caeeb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyleqOHICBjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "2b416b69-aa81-4150-9fb5-882e74a4f909"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:14, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.439600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3499554395675659,\n",
              " 'eval_f1': 0.8497409326424871,\n",
              " 'eval_runtime': 1.3457,\n",
              " 'eval_samples_per_second': 743.11,\n",
              " 'eval_steps_per_second': 46.816,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "'''\n",
        "<하드코딩>\n",
        "11번째 인코더 블록은 인덱스 165에서 시작합니다.\n",
        "이 블록 이전의 모든 층을 동결합니다.\n",
        "for index, (name, param) in enumerate(model.named_parameters()):\n",
        "if index < 165:\n",
        "param.requires_grad = False\n",
        "'''\n",
        "\n",
        "# 항상 11층이 165행부터가 아닐 수도 있기 때문에, 하드코딩 말고 동결시킬 레이어 층을 명시적으로 이용\n",
        "\n",
        "# BERT 전체 동결\n",
        "for param in model.bert.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# 몇 층까지 동결시킬지\n",
        "num_layers_to_freeze = 10\n",
        "\n",
        "# 11개 ~ 마지막 레이어층까진 그래디언트 계산 o\n",
        "for i in range(num_layers_to_freeze, 12):\n",
        "    for param in model.bert.encoder.layer[i].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Pooler 학습 (CLS 토큰 변환층)\n",
        "for param in model.bert.pooler.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 헤드(Classifier) 학습\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True  # ✏️\n",
        "\n",
        "# 훈련 과정을 실행할 Trainer 객체를 만듭니다.\n",
        "trainer = Trainer(\n",
        "   model=model,\n",
        "   args=training_args,\n",
        "   train_dataset=tokenized_train,\n",
        "   eval_dataset=tokenized_test,\n",
        "   processing_class=tokenizer,\n",
        "   data_collator=data_collator,\n",
        "   compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "# 0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### partial fine-tuning 이유\n",
        "\n",
        "1. 학습 속도 향상\n",
        "  - 동결된 층은 그래디언트 계산을 하지 않음\n",
        "\n",
        "\n",
        "2. 메모리 절약\n",
        "  - 그래디언트 저장 안 함 -> GPU 메모리 절약\n",
        "  \n",
        "\n",
        "3. 학습 안정성 향상 -> 과적합 방지\n",
        "  - 데이터 적을 때 -> 학습 파라미터 down -> 과적합 위험 down\n",
        "4. 사전 학습 지식 보존\n",
        "  - 하위 층의 일반적 언어 지식 유지\n",
        "  - Catastrophic Forgetting 방지\n",
        "  - 상위 층만 새 태스크에 특화 (ex: 감정 분석에 필요한 부분만 조정)\n",
        "5. 전이학습, 다중 태스크 학습 용이\n"
      ],
      "metadata": {
        "id": "ojlzbPN8wOF_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJRMWsLdA913"
      },
      "source": [
        "### **인코더 블록 동결의 효과**\n",
        "인코더 블록을 점차 훈련하면 모든 인코더 블록을 훈련했을 때의 성능과 거의 비슷한 수준에 도달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADvKJjNaFAot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d090279-2bb9-4cfc-9e77-d206c405743d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.375100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.375800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.377000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.379100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.381800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.384900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:23, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.390300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.399300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:22, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.415700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.436400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.458000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:19, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.516600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 시간이 오래 걸립니다!\n",
        "scores = []\n",
        "# 레이어를 하나씩 증가시키면서 어느 레이어까지 동결시켜야 (훈련시켜야) 성능이 좋은지 확인\n",
        "for index in range(12):\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "    # 인코더 블록 0-index를 동결합니다.\n",
        "    for name, param in model.named_parameters():\n",
        "        if \"layer\" in name:\n",
        "            layer_nr = int(name.split(\"layer\")[1].split(\".\")[1])\n",
        "            if layer_nr <= index:\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            param.requires_grad = True\n",
        "\n",
        "    # 모델 훈련\n",
        "    trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=tokenized_train,\n",
        "      eval_dataset=tokenized_test,\n",
        "      processing_class=tokenizer,\n",
        "      data_collator=data_collator,\n",
        "      compute_metrics=compute_metrics,\n",
        "    )\n",
        "    trainer.train()\n",
        "\n",
        "    # 평가\n",
        "    score = trainer.evaluate()[\"eval_f1\"]\n",
        "    scores.append(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWYlHFNdLQtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b022c989-8a1a-4519-85e0-71b938e750b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8840125391849529,\n",
              " 0.8840579710144928,\n",
              " 0.8840579710144928,\n",
              " 0.8778467908902692,\n",
              " 0.8775933609958506,\n",
              " 0.8746113989637305,\n",
              " 0.8731808731808732,\n",
              " 0.8652037617554859,\n",
              " 0.867570385818561,\n",
              " 0.8532778355879292,\n",
              " 0.8471074380165289,\n",
              " 0.8229166666666666]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kneed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuaDGQH0SERO",
        "outputId": "d8a64c95-c7f7-4c70-84f8-cea6e6dcf399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kneed\n",
            "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from kneed) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from kneed) (1.16.2)\n",
            "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: kneed\n",
            "Successfully installed kneed-0.8.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf3PIvKhOBJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "c84a110e-bda3-44e1-83c5-f2ceeacd7e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- 자동 탐지된 최적 동결 지점: 0-3\n",
            "- 해당 F1-score: 0.8676\n",
            "- 전체 학습(All) 대비 성능: 98.1%\n",
            "- 학습 레이어 비율: 33.3%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from kneed import KneeLocator\n",
        "\n",
        "# figure 객체를 만듭니다.\n",
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "x = [f\"0-{index}\" for index in range(12)]\n",
        "x[0] = \"None\"\n",
        "x[-1] = \"All\"\n",
        "y = scores[::-1]\n",
        "\n",
        "# 숫자 x축 (KneeLocator용)\n",
        "x_values = list(range(len(y)))\n",
        "\n",
        "# KneeLocator로 자동으로 최적점 찾기\n",
        "kn = KneeLocator(\n",
        "    x_values,\n",
        "    y,\n",
        "    curve='concave',      # 위로 볼록한 곡선\n",
        "    direction='increasing' # 증가하는 방향\n",
        ")\n",
        "optimal_point = kn.elbow\n",
        "\n",
        "# 그래프 스타일 설정\n",
        "plt.grid(color='#ECEFF1')\n",
        "\n",
        "# 자동으로 찾은 최적점에 선 그리기\n",
        "plt.axvline(x=optimal_point, color=\"#EC407A\", linestyle=\"--\")\n",
        "\n",
        "plt.title(\"Effect of Frozen Encoder Blocks on Training Performance\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.xlabel(\"Trainable encoder blocks\")\n",
        "\n",
        "# 그래프를 그립니다.\n",
        "plt.plot(x_values, y, color=\"black\", marker='o', markersize=4)\n",
        "\n",
        "# 그래프 주석 추가 (자동으로 찾은 지점)\n",
        "plt.annotate(\n",
        "    f'Performance stabilizing\\n({x[optimal_point]}, F1={y[optimal_point]:.3f})',\n",
        "    xy=(optimal_point, y[optimal_point]),\n",
        "    xytext=(optimal_point+0.5, y[optimal_point]-.05),\n",
        "    arrowprops=dict(\n",
        "        arrowstyle=\"-|>\",\n",
        "        connectionstyle=\"arc3\",\n",
        "        color=\"#00ACC1\")\n",
        ")\n",
        "\n",
        "# x축 레이블 설정\n",
        "plt.xticks(x_values, x, rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"multiple_frozen_blocks.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"- 자동 탐지된 최적 동결 지점: {x[optimal_point]}\")\n",
        "print(f\"- 해당 F1-score: {y[optimal_point]:.4f}\")\n",
        "print(f\"- 전체 학습(All) 대비 성능: {y[optimal_point]/y[-1]*100:.1f}%\")\n",
        "print(f\"- 학습 레이어 비율: {(optimal_point+1)/12*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gp-0sBdu6JRO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf785lzMjwiy"
      },
      "source": [
        "## **퓨-샷 분류**\n",
        "\n",
        "- **Few-Shot 분류** (Few-Shot Classification)\n",
        "    - 적은 수의 예제(few examples)만으로도 새로운 클래스를 분류할 수 있게 학습하는 방법\n",
        "        - 일반 학습: 클래스당 수천~수만 개\n",
        "        - Few-Shot 학습 : 클래스당 1~10개\n",
        "    - 사람이 동물 사진 1장만 보고 새로운 동물을 인식하는 것처럼,AI도 적은 예제로 새로운 것을 학습할 수 있게 만드는 기술\n",
        "    - 목표 = 빠른 적응력 (Quick Adaptation)\n",
        "    - 방법 = 메타 러닝 + 유사도 학습\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setfit**\n",
        "- https://huggingface.co/docs/setfit/index\n",
        "- 적은 양의 레이블 데이터만으로 문장 변환(**Sentence Transformer**) 모델을 효율적으로 파인튜닝하기 위한 프레임워크"
      ],
      "metadata": {
        "id": "hMHpuy1b6LUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **SetFit 알고리즘 세 단계**\n",
        "    1. **훈련 데이터 샘플링**\n",
        "        - 레이블이 있는 데이터를 같은 클래스끼리 묶거나 다른 클래스끼리 묶어서 (비슷한) 양성 문장 쌍과 (비슷하지 않은) 음성 문장 쌍을 생성\n",
        "    2. **임베딩 미세 튜닝**\n",
        "        - 앞서 생성한 훈련 데이터를 기반으로 사전 훈련된 임베딩 모델을 미세 튜닝함\n",
        "    3. **분류기 훈련**\n",
        "        - 임베딩 모델 위에 분류 헤드를 놓고 앞서 생성한 훈련 데이터를 사용해 훈련함"
      ],
      "metadata": {
        "id": "PLvNUUK26Le-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **일반 분류 vs SetFit 차이**\n",
        "---\n",
        "#### 일반 분류 방식 (Supervised Classification)\n",
        "- **학습 방식**: 각 문장과 정답 라벨을 직접 매칭하여 학습\n",
        "  * 예: \"영화 좋아요\" → 긍정(1), \"영화 별로\" → 부정(0)\n",
        "- **손실 함수**: CrossEntropy Loss\n",
        "  * 모델이 예측한 확률과 정답 라벨의 차이를 최소화\n",
        "- **필요 데이터**: 라벨당 수천~수만 개의 예시 필요\n",
        "  * 각 클래스별로 충분한 변형(variation)을 학습해야 함\n",
        "- **단점**: 적은 데이터에서는 과적합 발생 쉬움\n",
        "  * 10개 예시로는 패턴 학습 불가능, 암기만 함\n",
        "---\n",
        "#### SetFit 방식 (Contrastive Learning)\n",
        "- **학습 방식**: 문장 간 유사도 관계를 학습\n",
        "  * 같은 클래스 문장 쌍 → \"이 둘은 비슷해\" (양성 쌍)\n",
        "  * 다른 클래스 문장 쌍 → \"이 둘은 달라\" (음성 쌍)\n",
        "- **쌍 생성으로 데이터 증폭** (triplet ❌, pair 방식)\n",
        "  - 총 32문장 (2개 클래스, 클래스당 16개)\n",
        "  - 각 문장당 positive pair, negative pair (2개)\n",
        "  - pair 샘플링 생성 반복 횟수 = 20\n",
        "  - 32 * 2 * 20 = 1,280 개\n",
        "  - 32개 -> 1,280 개로 증폭\n",
        "- **손실 함수**: Contrastive Loss\n",
        "  * 같은 클래스: 벡터 간 거리를 가까이 (minimize)\n",
        "  * 다른 클래스: 벡터 간 거리를 멀게 (maximize)\n",
        "  * Loss = max(0, d(양성 쌍) - d(음성 쌍) + margin)\n",
        "- **벡터 공간 정리**:\n",
        "  * 같은 라벨 → 클러스터로 뭉침\n",
        "  * 다른 라벨 → 서로 멀어짐\n",
        "  * 결과: 명확하게 구분되는 공간 형성\n",
        "- **분류 단계**:\n",
        "  * 정리된 벡터 공간에 간단한 분류기(Logistic Regression) 추가\n",
        "  * 이미 공간이 잘 정리되어 있어 적은 데이터로도 충분\n",
        "- **장점**:\n",
        "  * 쌍 생성으로 학습 데이터 증폭\n",
        "  * 유사도 학습이 라벨 예측보다 쉬움\n",
        "  * 사전 학습된 Sentence Transformer 활용으로 빠른 수렴"
      ],
      "metadata": {
        "id": "TlTbTF0nxOF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SetFit: 소량의 샘플로 효율적인 미세 튜닝하기**"
      ],
      "metadata": {
        "id": "_KPwopm27PW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setfit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehutRkUFpB9W",
        "outputId": "7c6836d6-1cfd-4aac-935f-ebc46a26ac5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setfit in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: datasets>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from setfit) (4.0.0)\n",
            "Requirement already satisfied: sentence-transformers>=3 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers[train]>=3->setfit) (5.1.1)\n",
            "Requirement already satisfied: transformers>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from setfit) (4.57.1)\n",
            "Requirement already satisfied: evaluate>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from setfit) (0.4.6)\n",
            "Requirement already satisfied: huggingface_hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from setfit) (0.35.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from setfit) (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from setfit) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.15.0->setfit) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24.0->setfit) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24.0->setfit) (1.1.10)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (11.3.0)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers[train]>=3->setfit) (1.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.41.0->setfit) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.41.0->setfit) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.41.0->setfit) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->setfit) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->setfit) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (5.9.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (3.13.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.15.0->setfit) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.15.0->setfit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.15.0->setfit) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.15.0->setfit) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.15.0->setfit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ybeQ3j6kOk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21526f95-fc79-4e99-d8ad-7b0d249a11cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['Unnamed: 0', 'id', 'document', 'label'],\n",
              "    num_rows: 32\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "from setfit import sample_dataset\n",
        "\n",
        "# 퓨-샷 설정을 흉내내기 위해 클래스마다 16개의 샘플을 선택합니다. (총 32개)\n",
        "sampled_train_data = sample_dataset(train_data, num_samples=16, seed = 42)\n",
        "sampled_train_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- jhgan/ko-sroberta-multitask :\n",
        "  - Sentence-RoBERTa (임베딩 특화)\n",
        "  - KorNLI, KorSTS 등 다중 태스크 학습\n",
        "  - Contrastive Learning 기반\n",
        "  - 한국어 문장 유사도 최고 성능"
      ],
      "metadata": {
        "id": "JLt9uFEy77mb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 왜 모델이 다를까?\n",
        "\n",
        "### Layer Freezing: klue/bert-base\n",
        "```\n",
        "데이터: 8,500개 (충분)\n",
        "학습: 직접 분류 (라벨 예측)\n",
        "목적: 범용 → 특화\n",
        "\n",
        "→ 범용 BERT로 충분히 학습 가능\n",
        "```\n",
        "\n",
        "### Few-shot: jhgan/ko-sroberta-multitask\n",
        "```\n",
        "데이터: 32개 (매우 적음!)\n",
        "학습: 유사도 기반 (Contrastive)\n",
        "목적: 임베딩 품질이 핵심\n",
        "\n",
        "→ 이미 좋은 임베딩 필수!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 핵심 차이\n",
        "\n",
        "| | Layer Freezing | Few-shot |\n",
        "|---|---|---|\n",
        "| 데이터 | 많음 (8.5K) | 적음 (32) |\n",
        "| 모델 의존도 | 낮음 | **매우 높음** |\n",
        "| 필요 능력 | 분류 | **임베딩** |\n",
        "\n",
        "**적은 데이터 = 더 좋은 출발점 필요!**\n",
        "\n",
        "jhgan/ko-sroberta-multitask는:\n",
        "- ✅ Sentence Transformer (임베딩 특화)\n",
        "- ✅ Contrastive Learning (Few-shot과 동일)\n",
        "- ✅ 다중 태스크 학습 (범용성)\n",
        "\n",
        "→ 32개로도 높은 성능"
      ],
      "metadata": {
        "id": "lLP91hsyz3z7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y55TDrmSqHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e10e2f9-f78d-4737-cb96-7886e2ee76cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from setfit import SetFitModel\n",
        "\n",
        "# 사전 훈련된 SentenceTransformer 모델을 로드합니다.\n",
        "# 분류 헤드(분류기)를 직접 지정하지 않으면, default LogisticRegression 사용함\n",
        "model = SetFitModel.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구조 확인\n",
        "print(\"=\" * 70)\n",
        "print(\"SetFit 모델 전체 구조\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 1. model_body (Sentence Transformer) 파라미터\n",
        "print(\"\\n[Part 1] model_body (Sentence Transformer) 파라미터:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "i = 0\n",
        "for name, param in model.model_body.named_parameters():\n",
        "    print(f'{i}: {name} ----- {param.requires_grad} --- {param.shape}')\n",
        "    i += 1\n",
        "\n",
        "print(f\"\\n총 {i}개 파라미터\")\n",
        "\n",
        "# 2. model_head (Classifier) - sklearn이라 named_parameters 없음\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[Part 2] model_head (Classifier):\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "if model.model_head is not None:\n",
        "    print(f\"타입: {type(model.model_head)}\")\n",
        "\n",
        "    # sklearn 모델이 학습되었다면\n",
        "    if hasattr(model.model_head, 'coef_'):\n",
        "        print(f\"가중치 (coef_): {model.model_head.coef_.shape}\")\n",
        "        print(f\"편향 (intercept_): {model.model_head.intercept_.shape}\")\n",
        "        print(f\"클래스: {model.model_head.classes_}\")\n",
        "    else:\n",
        "        print(\"아직 학습되지 않음 (coef_ 속성 없음)\")\n",
        "else:\n",
        "    print(\"None (아직 초기화 안 됨)\")\n",
        "\n",
        "# 3. 전체 속성 확인\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[Part 3] SetFit 모델의 모든 속성:\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for attr_name, attr_value in vars(model).items():\n",
        "    print(f\"{attr_name}: {type(attr_value).__name__}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97_kaFA64AgC",
        "outputId": "cbb80252-a542-470d-fec5-b5e1f5370045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SetFit 모델 전체 구조\n",
            "======================================================================\n",
            "\n",
            "[Part 1] model_body (Sentence Transformer) 파라미터:\n",
            "----------------------------------------------------------------------\n",
            "0: 0.auto_model.embeddings.word_embeddings.weight ----- True --- torch.Size([32000, 768])\n",
            "1: 0.auto_model.embeddings.position_embeddings.weight ----- True --- torch.Size([514, 768])\n",
            "2: 0.auto_model.embeddings.token_type_embeddings.weight ----- True --- torch.Size([1, 768])\n",
            "3: 0.auto_model.embeddings.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "4: 0.auto_model.embeddings.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "5: 0.auto_model.encoder.layer.0.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "6: 0.auto_model.encoder.layer.0.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "7: 0.auto_model.encoder.layer.0.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "8: 0.auto_model.encoder.layer.0.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "9: 0.auto_model.encoder.layer.0.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "10: 0.auto_model.encoder.layer.0.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "11: 0.auto_model.encoder.layer.0.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "12: 0.auto_model.encoder.layer.0.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "13: 0.auto_model.encoder.layer.0.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "14: 0.auto_model.encoder.layer.0.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "15: 0.auto_model.encoder.layer.0.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "16: 0.auto_model.encoder.layer.0.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "17: 0.auto_model.encoder.layer.0.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "18: 0.auto_model.encoder.layer.0.output.dense.bias ----- True --- torch.Size([768])\n",
            "19: 0.auto_model.encoder.layer.0.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "20: 0.auto_model.encoder.layer.0.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "21: 0.auto_model.encoder.layer.1.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "22: 0.auto_model.encoder.layer.1.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "23: 0.auto_model.encoder.layer.1.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "24: 0.auto_model.encoder.layer.1.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "25: 0.auto_model.encoder.layer.1.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "26: 0.auto_model.encoder.layer.1.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "27: 0.auto_model.encoder.layer.1.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "28: 0.auto_model.encoder.layer.1.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "29: 0.auto_model.encoder.layer.1.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "30: 0.auto_model.encoder.layer.1.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "31: 0.auto_model.encoder.layer.1.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "32: 0.auto_model.encoder.layer.1.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "33: 0.auto_model.encoder.layer.1.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "34: 0.auto_model.encoder.layer.1.output.dense.bias ----- True --- torch.Size([768])\n",
            "35: 0.auto_model.encoder.layer.1.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "36: 0.auto_model.encoder.layer.1.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "37: 0.auto_model.encoder.layer.2.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "38: 0.auto_model.encoder.layer.2.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "39: 0.auto_model.encoder.layer.2.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "40: 0.auto_model.encoder.layer.2.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "41: 0.auto_model.encoder.layer.2.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "42: 0.auto_model.encoder.layer.2.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "43: 0.auto_model.encoder.layer.2.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "44: 0.auto_model.encoder.layer.2.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "45: 0.auto_model.encoder.layer.2.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "46: 0.auto_model.encoder.layer.2.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "47: 0.auto_model.encoder.layer.2.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "48: 0.auto_model.encoder.layer.2.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "49: 0.auto_model.encoder.layer.2.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "50: 0.auto_model.encoder.layer.2.output.dense.bias ----- True --- torch.Size([768])\n",
            "51: 0.auto_model.encoder.layer.2.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "52: 0.auto_model.encoder.layer.2.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "53: 0.auto_model.encoder.layer.3.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "54: 0.auto_model.encoder.layer.3.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "55: 0.auto_model.encoder.layer.3.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "56: 0.auto_model.encoder.layer.3.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "57: 0.auto_model.encoder.layer.3.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "58: 0.auto_model.encoder.layer.3.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "59: 0.auto_model.encoder.layer.3.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "60: 0.auto_model.encoder.layer.3.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "61: 0.auto_model.encoder.layer.3.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "62: 0.auto_model.encoder.layer.3.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "63: 0.auto_model.encoder.layer.3.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "64: 0.auto_model.encoder.layer.3.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "65: 0.auto_model.encoder.layer.3.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "66: 0.auto_model.encoder.layer.3.output.dense.bias ----- True --- torch.Size([768])\n",
            "67: 0.auto_model.encoder.layer.3.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "68: 0.auto_model.encoder.layer.3.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "69: 0.auto_model.encoder.layer.4.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "70: 0.auto_model.encoder.layer.4.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "71: 0.auto_model.encoder.layer.4.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "72: 0.auto_model.encoder.layer.4.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "73: 0.auto_model.encoder.layer.4.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "74: 0.auto_model.encoder.layer.4.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "75: 0.auto_model.encoder.layer.4.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "76: 0.auto_model.encoder.layer.4.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "77: 0.auto_model.encoder.layer.4.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "78: 0.auto_model.encoder.layer.4.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "79: 0.auto_model.encoder.layer.4.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "80: 0.auto_model.encoder.layer.4.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "81: 0.auto_model.encoder.layer.4.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "82: 0.auto_model.encoder.layer.4.output.dense.bias ----- True --- torch.Size([768])\n",
            "83: 0.auto_model.encoder.layer.4.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "84: 0.auto_model.encoder.layer.4.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "85: 0.auto_model.encoder.layer.5.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "86: 0.auto_model.encoder.layer.5.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "87: 0.auto_model.encoder.layer.5.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "88: 0.auto_model.encoder.layer.5.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "89: 0.auto_model.encoder.layer.5.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "90: 0.auto_model.encoder.layer.5.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "91: 0.auto_model.encoder.layer.5.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "92: 0.auto_model.encoder.layer.5.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "93: 0.auto_model.encoder.layer.5.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "94: 0.auto_model.encoder.layer.5.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "95: 0.auto_model.encoder.layer.5.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "96: 0.auto_model.encoder.layer.5.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "97: 0.auto_model.encoder.layer.5.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "98: 0.auto_model.encoder.layer.5.output.dense.bias ----- True --- torch.Size([768])\n",
            "99: 0.auto_model.encoder.layer.5.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "100: 0.auto_model.encoder.layer.5.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "101: 0.auto_model.encoder.layer.6.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "102: 0.auto_model.encoder.layer.6.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "103: 0.auto_model.encoder.layer.6.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "104: 0.auto_model.encoder.layer.6.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "105: 0.auto_model.encoder.layer.6.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "106: 0.auto_model.encoder.layer.6.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "107: 0.auto_model.encoder.layer.6.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "108: 0.auto_model.encoder.layer.6.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "109: 0.auto_model.encoder.layer.6.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "110: 0.auto_model.encoder.layer.6.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "111: 0.auto_model.encoder.layer.6.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "112: 0.auto_model.encoder.layer.6.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "113: 0.auto_model.encoder.layer.6.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "114: 0.auto_model.encoder.layer.6.output.dense.bias ----- True --- torch.Size([768])\n",
            "115: 0.auto_model.encoder.layer.6.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "116: 0.auto_model.encoder.layer.6.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "117: 0.auto_model.encoder.layer.7.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "118: 0.auto_model.encoder.layer.7.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "119: 0.auto_model.encoder.layer.7.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "120: 0.auto_model.encoder.layer.7.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "121: 0.auto_model.encoder.layer.7.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "122: 0.auto_model.encoder.layer.7.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "123: 0.auto_model.encoder.layer.7.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "124: 0.auto_model.encoder.layer.7.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "125: 0.auto_model.encoder.layer.7.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "126: 0.auto_model.encoder.layer.7.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "127: 0.auto_model.encoder.layer.7.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "128: 0.auto_model.encoder.layer.7.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "129: 0.auto_model.encoder.layer.7.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "130: 0.auto_model.encoder.layer.7.output.dense.bias ----- True --- torch.Size([768])\n",
            "131: 0.auto_model.encoder.layer.7.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "132: 0.auto_model.encoder.layer.7.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "133: 0.auto_model.encoder.layer.8.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "134: 0.auto_model.encoder.layer.8.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "135: 0.auto_model.encoder.layer.8.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "136: 0.auto_model.encoder.layer.8.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "137: 0.auto_model.encoder.layer.8.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "138: 0.auto_model.encoder.layer.8.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "139: 0.auto_model.encoder.layer.8.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "140: 0.auto_model.encoder.layer.8.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "141: 0.auto_model.encoder.layer.8.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "142: 0.auto_model.encoder.layer.8.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "143: 0.auto_model.encoder.layer.8.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "144: 0.auto_model.encoder.layer.8.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "145: 0.auto_model.encoder.layer.8.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "146: 0.auto_model.encoder.layer.8.output.dense.bias ----- True --- torch.Size([768])\n",
            "147: 0.auto_model.encoder.layer.8.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "148: 0.auto_model.encoder.layer.8.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "149: 0.auto_model.encoder.layer.9.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "150: 0.auto_model.encoder.layer.9.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "151: 0.auto_model.encoder.layer.9.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "152: 0.auto_model.encoder.layer.9.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "153: 0.auto_model.encoder.layer.9.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "154: 0.auto_model.encoder.layer.9.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "155: 0.auto_model.encoder.layer.9.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "156: 0.auto_model.encoder.layer.9.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "157: 0.auto_model.encoder.layer.9.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "158: 0.auto_model.encoder.layer.9.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "159: 0.auto_model.encoder.layer.9.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "160: 0.auto_model.encoder.layer.9.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "161: 0.auto_model.encoder.layer.9.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "162: 0.auto_model.encoder.layer.9.output.dense.bias ----- True --- torch.Size([768])\n",
            "163: 0.auto_model.encoder.layer.9.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "164: 0.auto_model.encoder.layer.9.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "165: 0.auto_model.encoder.layer.10.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "166: 0.auto_model.encoder.layer.10.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "167: 0.auto_model.encoder.layer.10.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "168: 0.auto_model.encoder.layer.10.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "169: 0.auto_model.encoder.layer.10.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "170: 0.auto_model.encoder.layer.10.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "171: 0.auto_model.encoder.layer.10.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "172: 0.auto_model.encoder.layer.10.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "173: 0.auto_model.encoder.layer.10.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "174: 0.auto_model.encoder.layer.10.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "175: 0.auto_model.encoder.layer.10.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "176: 0.auto_model.encoder.layer.10.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "177: 0.auto_model.encoder.layer.10.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "178: 0.auto_model.encoder.layer.10.output.dense.bias ----- True --- torch.Size([768])\n",
            "179: 0.auto_model.encoder.layer.10.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "180: 0.auto_model.encoder.layer.10.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "181: 0.auto_model.encoder.layer.11.attention.self.query.weight ----- True --- torch.Size([768, 768])\n",
            "182: 0.auto_model.encoder.layer.11.attention.self.query.bias ----- True --- torch.Size([768])\n",
            "183: 0.auto_model.encoder.layer.11.attention.self.key.weight ----- True --- torch.Size([768, 768])\n",
            "184: 0.auto_model.encoder.layer.11.attention.self.key.bias ----- True --- torch.Size([768])\n",
            "185: 0.auto_model.encoder.layer.11.attention.self.value.weight ----- True --- torch.Size([768, 768])\n",
            "186: 0.auto_model.encoder.layer.11.attention.self.value.bias ----- True --- torch.Size([768])\n",
            "187: 0.auto_model.encoder.layer.11.attention.output.dense.weight ----- True --- torch.Size([768, 768])\n",
            "188: 0.auto_model.encoder.layer.11.attention.output.dense.bias ----- True --- torch.Size([768])\n",
            "189: 0.auto_model.encoder.layer.11.attention.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "190: 0.auto_model.encoder.layer.11.attention.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "191: 0.auto_model.encoder.layer.11.intermediate.dense.weight ----- True --- torch.Size([3072, 768])\n",
            "192: 0.auto_model.encoder.layer.11.intermediate.dense.bias ----- True --- torch.Size([3072])\n",
            "193: 0.auto_model.encoder.layer.11.output.dense.weight ----- True --- torch.Size([768, 3072])\n",
            "194: 0.auto_model.encoder.layer.11.output.dense.bias ----- True --- torch.Size([768])\n",
            "195: 0.auto_model.encoder.layer.11.output.LayerNorm.weight ----- True --- torch.Size([768])\n",
            "196: 0.auto_model.encoder.layer.11.output.LayerNorm.bias ----- True --- torch.Size([768])\n",
            "197: 0.auto_model.pooler.dense.weight ----- True --- torch.Size([768, 768])\n",
            "198: 0.auto_model.pooler.dense.bias ----- True --- torch.Size([768])\n",
            "\n",
            "총 199개 파라미터\n",
            "\n",
            "======================================================================\n",
            "[Part 2] model_head (Classifier):\n",
            "----------------------------------------------------------------------\n",
            "타입: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
            "아직 학습되지 않음 (coef_ 속성 없음)\n",
            "\n",
            "======================================================================\n",
            "[Part 3] SetFit 모델의 모든 속성:\n",
            "----------------------------------------------------------------------\n",
            "_hub_mixin_config: dict\n",
            "model_body: SentenceTransformer\n",
            "model_head: LogisticRegression\n",
            "multi_target_strategy: NoneType\n",
            "normalize_embeddings: bool\n",
            "labels: NoneType\n",
            "model_card_data: SetFitModelCardData\n",
            "sentence_transformers_kwargs: dict\n",
            "attributes_to_save: set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **AutoModelForSequenceClassification vs SetFitModel 구조 차이**\n",
        "\n",
        "#### AutoModelForSequenceClassification\n",
        "```\n",
        "embeddings.word_embeddings.weight\n",
        "embeddings.position_embeddings.weight\n",
        "embeddings.token_type_embeddings.weight\n",
        "embeddings.LayerNorm.weight\n",
        "embeddings.LayerNorm.bias\n",
        "encoder.layer.0.attention.self.query.weight\n",
        "encoder.layer.0.attention.self.key.weight\n",
        "...\n",
        "encoder.layer.11.output.dense.weight\n",
        "encoder.layer.11.output.LayerNorm.bias\n",
        "pooler.dense.weight\n",
        "pooler.dense.bias\n",
        "classifier.weight  ← PyTorch Linear 레이어\n",
        "classifier.bias\n",
        "```\n",
        "- **단일 PyTorch 모델**: 임베딩부터 분류까지 모두 PyTorch\n",
        "- **전체 110M+ 파라미터**가 하나의 모델에 포함\n",
        "- `named_parameters()`로 모든 레이어 확인 가능\n",
        "- **분류 헤드**: PyTorch Linear 레이어 (학습 가능)\n",
        "\n",
        "---\n",
        "\n",
        "### SetFitModel\n",
        "```\n",
        "model_body (Sentence Transformer):\n",
        "  0.auto_model.embeddings.word_embeddings.weight\n",
        "  0.auto_model.embeddings.position_embeddings.weight\n",
        "  ...\n",
        "  0.auto_model.encoder.layer.11.output.LayerNorm.weight\n",
        "  0.auto_model.encoder.layer.11.output.LayerNorm.bias\n",
        "  0.auto_model.encoder.relative_attention_bias.weight\n",
        "  0.auto_model.pooler.dense.weight  ← Pooler (여기서 끝)\n",
        "  0.auto_model.pooler.dense.bias\n",
        "  (Pooling 레이어는 파라미터 없음 - mean pooling)\n",
        "\n",
        "model_head (Classifier):\n",
        "  sklearn.LogisticRegression\n",
        "  - coef_: ndarray shape (num_classes, 768)\n",
        "  - intercept_: ndarray shape (num_classes,)\n",
        "```\n",
        "- **2단계 분리 구조**:\n",
        "  - `model_body`: Sentence Transformer (PyTorch, Pooler까지 포함)\n",
        "  - `model_head`: LogisticRegression (sklearn, NumPy)\n",
        "- **Pooler까지만** PyTorch 파라미터\n",
        "- **분류 헤드**: sklearn 모델 (NumPy 배열, `named_parameters()` 불가)\n",
        "- Pooling 레이어는 파라미터 없는 연산만 수행 (mean pooling)\n",
        "\n",
        "---\n",
        "\n",
        "### 핵심 차이\n",
        "\n",
        "| 구분 | AutoModel | SetFit |\n",
        "|------|-----------|--------|\n",
        "| 구조 | 단일 PyTorch | PyTorch + sklearn |\n",
        "| 마지막 학습 가능 레이어 | classifier | pooler |\n",
        "| 분류기 | Linear (torch.nn) | LogisticRegression (sklearn) |\n",
        "| 파라미터 확인 | `named_parameters()` 전체 | `model_body.named_parameters()` 만 |\n",
        "| 학습 방식 | 엔드-투-엔드 | 2단계 (Contrastive → 분류) |"
      ],
      "metadata": {
        "id": "-D_mxmUc7T91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-Shot fine-tuning 하기 전"
      ],
      "metadata": {
        "id": "d-CONWdk3xd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 사전학습 모델 그대로 (baseline)\n",
        "model_base = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"jhgan/ko-sroberta-multitask\",\n",
        "    num_labels=2\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
        "\n",
        "tokenized_train = sampled_train_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "714d876d8fa94829a06f0615b20f8ebe",
            "4564d44396f046589680cb099cd913f0",
            "9b628043ffe943ce959975639030dd0c",
            "c7faed702c84440392ea315f3f14f1ee",
            "c8fb0ff755d14ea493bf83ec5328e487",
            "5169a3e56b434cebbaa0111ce6dfd621",
            "efe32cff83844de9af7a5cd40e02e4bf",
            "9cbed5ebe93345408c558e0e9babcd74",
            "2ea974ae02b04b07a11593249ab8fb2b",
            "e68761eb68e74af2a4c559bc47f0581e",
            "91f64f35c65145dcb46e6c10182deecf"
          ]
        },
        "id": "xCxeLlIQ2Tc7",
        "outputId": "b2b25759-2653-475f-f7de-4a73093d1d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at jhgan/ko-sroberta-multitask and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "714d876d8fa94829a06f0615b20f8ebe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "yTc7kpPa3mcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 일반 파인튜닝\n",
        "trainer_base = Trainer(\n",
        "    model=model_base,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "trainer_base.train()\n",
        "metrics_base = trainer_base.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "HpnAKQ-M3Poz",
        "outputId": "62d58882-ebe3-451c-f807-360b9f80ab5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_base.evaluate()\n",
        "# 0.88 (8500개 훈련 데이터로)\n",
        "# 0.654 (few-shot 훈련용 샘플 데이터로)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "kp3GXDvP36Qs",
        "outputId": "e5e1f31d-1f18-41a4-f8cb-44ea983c4cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='126' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6849080324172974,\n",
              " 'eval_f1': 0.6543385490753911,\n",
              " 'eval_runtime': 1.4966,\n",
              " 'eval_samples_per_second': 668.194,\n",
              " 'eval_steps_per_second': 42.096,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model head 확인하기\n",
        "model.model_head\n",
        "\n",
        "# 모델이 학습되지 않아서 주황색으로 나타남\n",
        "# 학습한 상태는 하늘색"
      ],
      "metadata": {
        "id": "oyQzGrULBGja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "aca43abd-c927-4038-c08c-39dd1e7ed55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Few-shot fine-tuning 한 후"
      ],
      "metadata": {
        "id": "4BH7f3xj4GJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ10SpAXdNvC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "b0c3226e9a94447abe1d994fa7218cf9",
            "c029e34148ce47028a27ef2a43016d40",
            "63b02d95024f4a9ca18738cefb05dc5a",
            "c8cceeb57293412bbd72f5298c2174ce",
            "2c868108496445bc8f70d818d05918f5",
            "4635edaee95e4b21ade488a502e6004a",
            "cd5f13301a6648be8747c54d16494b09",
            "fea6edc3da904c4dac183ebcba6e2279",
            "c35999d8f2e442f78c1fa4d1c28e5d07",
            "0a6f86284d3345ca9415a5106a811c8f",
            "88aa14b25af745a4ae7a7167f36f08a4"
          ]
        },
        "outputId": "e9f672c2-d52a-4e0b-c9cd-05435e81ed6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0c3226e9a94447abe1d994fa7218cf9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from setfit import TrainingArguments as SetFitTrainingArguments\n",
        "from setfit import Trainer as SetFitTrainer\n",
        "\n",
        "# 훈련 매개변수를 정의합니다.\n",
        "args = SetFitTrainingArguments(\n",
        "    num_epochs=3,      # 대조 학습을 수행할 에포크 횟수\n",
        "    num_iterations=30,  # 한 에포크당 pair 샘플링 생성 반복 횟수 (32 * 2 * num_iterations)\n",
        "    # batch_size = 16 (default)\n",
        ")\n",
        "args.eval_strategy = args.evaluation_strategy\n",
        "\n",
        "# Trainer 객체를 만듭니다.\n",
        "trainer = SetFitTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=sampled_train_data,\n",
        "    eval_dataset=test_data,\n",
        "    metric=\"f1\",\n",
        "    column_mapping={\"document\": \"text\"}  # default required columns = ['text', 'label']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoVvXBiV6Lmu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "b490bb47-4b38-4e28-9863-24bbb287cb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 1920\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 00:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# 훈련 루프\n",
        "trainer.train()\n",
        "\n",
        "# wandb(Weights & Biases):\n",
        "# 머신러닝 모델의 훈련 과정(손실, 정확도 등)과 결과물을 자동으로 기록하고 시각화하여\n",
        "# 실험을 체계적으로 관리하고 다른 실험과 비교할 수 있게 도와주는 MLOps(기계 학습 운영) 도구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyRxiY32R3Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f6e1b9-eaf2-4037-fa7a-bbec94cb5b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'f1': 0.7577777777777778}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# 테스트 데이터에서 모델을 평가합니다.\n",
        "trainer.evaluate()\n",
        "# 0.78 - 샘플링 생성 횟수가 20개일때\n",
        "# 0.75 - 샘플링 생성 횟수가 30개일때"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 실험할 num_iterations 범위\n",
        "iterations_range = [5, 10, 15, 20, 25, 30, 35, 40]\n",
        "f1_scores = []\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"num_iterations별 성능 측정 중...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for n_iter in iterations_range:\n",
        "    # 모델 초기화\n",
        "    model = SetFitModel.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
        "\n",
        "    # 학습 설정\n",
        "    args = SetFitTrainingArguments(\n",
        "        num_epochs=3,\n",
        "        num_iterations=n_iter,\n",
        "        batch_size=16\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = SetFitTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=sampled_train_data,\n",
        "        eval_dataset=test_data,\n",
        "        metric=\"f1\",\n",
        "        column_mapping={\"document\": \"text\"}\n",
        "    )\n",
        "\n",
        "    # 학습 및 평가\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    f1 = metrics['f1']\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"num_iterations={n_iter:2d}: F1={f1:.4f}\")\n",
        "\n",
        "# 최적값 찾기\n",
        "best_idx = f1_scores.index(max(f1_scores))\n",
        "best_iter = iterations_range[best_idx]\n",
        "best_f1 = f1_scores[best_idx]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"최적 num_iterations: {best_iter}\")\n",
        "print(f\"최고 F1 Score: {best_f1:.4f}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(iterations_range, f1_scores, marker='o', linewidth=2, markersize=8)\n",
        "plt.axvline(x=best_iter, color='r', linestyle='--', label=f'최적값: {best_iter}')\n",
        "plt.axhline(y=best_f1, color='r', linestyle='--', alpha=0.3)\n",
        "\n",
        "# 최적점 강조\n",
        "plt.scatter([best_iter], [best_f1], color='red', s=200, zorder=5,\n",
        "            label=f'Best: {best_f1:.4f}')\n",
        "\n",
        "# 과적합 영역 표시\n",
        "if best_idx < len(iterations_range) - 1:\n",
        "    plt.axvspan(iterations_range[best_idx], iterations_range[-1],\n",
        "                alpha=0.2, color='red', label='과적합 영역')\n",
        "\n",
        "plt.xlabel('num_iterations', fontsize=12)\n",
        "plt.ylabel('F1 Score', fontsize=12)\n",
        "plt.title('num_iterations에 따른 Few-shot 성능 변화', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n그래프 저장 완료: fewshot_iterations_analysis.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f325c3dd1a64045b47c09cc64337f48",
            "72488c7542eb4088846266b4d404e3fc",
            "f3d49f7900bb42e3bff1e0d9e157c7ee",
            "f3ac07a453c54fc0b2af92acf2eaf913",
            "3fee2f179e1041c1925074abd951d5e5",
            "7ebdab09351c46f090dd4f307f62d9e2",
            "fb10fe0148724e9db04461d87d79a2b1",
            "79dd66e0d29e4e8fb3eff8e7d9d79f52",
            "0d140501dd094867b9a964518a7eb4a0",
            "f222c4672fbe4f64b30e00c7b79dc794",
            "c384e17eef8046efbf5ae2390ff2241c",
            "bcfe617293d5413ba82c573816697dfc",
            "f1f4ee3baf1645b1a12407cbc14b8c94",
            "5cb3b53f39b04109a8a3632443597ad8",
            "c237ae77e3a24ec4b89aba536dab43bd",
            "6d55b90a4574472e8e7ce432d76f0c6f",
            "b4ff2d28906343e5836501a594794122",
            "3beb8d269f824b7ba006a5d2d04f8d09",
            "e03aacf5d9604072b7f657a2b1401a06",
            "5512c6ae3a88433d929dda1023dda1e5",
            "9883b8e0e3504611b8671a00034d8cf9",
            "512aae7094f844d09444923cc9919f19",
            "e7f73d4cb2144219a66f3914a46f0e07",
            "67e420d3890c4649908fc130872bd031",
            "633f45d89a7546e585b0d7d58ab812be",
            "13947736784541159d08977c47c0d264",
            "44ebc5982ccf48f5a5931ff0678302a7",
            "13ba8b8723f94790ac14ee2030ee8ea1",
            "73154ae078ae487a8d8be06c3355e39f",
            "a5f045cc2c0c432c855bb45bc5b8c456",
            "5f9d8f5050a1412d9dc61b6bfc860714",
            "ecfaf47727fa46fc856a02d07cfd2d1e",
            "eb37e37ec47846249fccd1aef82bb827",
            "d48b4570b2e04c39974887f680026e33",
            "cff5158217f844dca5f0798b8399feed",
            "9ae688ae431340e8b1e228fb33aec19c",
            "aacae62c957a4bfea276166f6c755f21",
            "11cb758508dd4a2eb97c9f34a7ea566d",
            "9ba22a7f708b4d22b6917d0b8f6791e3",
            "8fd091858e54419b843c30aee8868a3b",
            "550e314c89f344aba9290f32cd1b52cd",
            "2b7a76e2ea454928bdc7f97989495800",
            "220a995baf544ab5ac7917429f1ea4a3",
            "5f7ddf751bb042e9a2505133f8478dfe",
            "974c74b295394ea09ec2a84b06bc8655",
            "295cbd30496d4a56bbb13927e0e4d26c",
            "c04fa8a00d4646b2b0321e2e0c895497",
            "cf4e8006290f4d62a3b1c8ee6871932f",
            "55c663607b074bb291af160f422a3ae5",
            "eb8e7762be7a46f5aac9c0270b17ce48",
            "937b55de5177483b8f9e972e51f93e6e",
            "466f714583b04b868be2908ebf486fac",
            "764b7c693f8545e3b52f16a13aee1150",
            "efaf8e84a9524985b68f297eef4a805f",
            "7d54cae9c2d14d1e8592aa20aef1c9c1",
            "f46edb28212e4544a1a223ed85b0c901",
            "47cfee82c4e64b6bae40e67454b0267d",
            "70b904c810e4418fb98bf6fe1b4c4f62",
            "0025c3b513044804a53a1d0f3325ce4e",
            "18296b3ad9744ecabf632ff9e1111131",
            "470f9c1a561d41539925822dfd924855",
            "48e50b47417444409bce7f337124a446",
            "de7a5a941c3f416f8ccad83e1ed13a27",
            "7b3948dbf4634bf3ae7bba1f6fad96b1",
            "c205534bd3c541e28f548ff9d995a7a9",
            "7cecf6e07f1a421b82ec357d502f3377",
            "76cb7d675c2648f4a5e397fa1a533bb6",
            "c55219f35b0240df936e3df2bd930774",
            "59fec431982c4e04b2b81a0950a08005",
            "56153d5fa9094506b90f4f66241445f2",
            "0c334190043e447c9daf35ada290f4a7",
            "ed8b6bb0adad4e468a7a77510752c1e6",
            "a560b06021b54b078c7ea22e9bdc1581",
            "c152f731d72e4c7ea9fa71bc7259feed",
            "926b9007ca1b45e688e97950b4a29d35",
            "9a8e32ecce904fa18172fef2e3e0c7c5",
            "d12ed6fdb4fd45af91a0aff10ea3ea85",
            "963c57d8e8cf45bb80c4bd5b737b34d4",
            "d9de07f0f4bb4f3995ae76b80c2da81a",
            "3256712795e942e1bb014d930eab1605",
            "14d159a9d30b4a6a9c3095b66d156c0e",
            "cc8a98d3383f46498259ca403468ada2",
            "05d2143025a64c498c86ed57ca56be4c",
            "fcc9d6b6854b440ca3b206419d555e57",
            "36a68ad69fc544bb887336a111313b8c",
            "766349baf9a74e89bcf598bac0eed086",
            "887a37c40902474ba3feb987d2eebc2f",
            "a4521c1705b04fce98bba5f91426c8a7"
          ]
        },
        "id": "Y68GPzlg7ws4",
        "outputId": "ff71df40-a920-46fd-847d-0270e9bf1b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "num_iterations별 성능 측정 중...\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f325c3dd1a64045b47c09cc64337f48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 320\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.344300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.067800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations= 5: F1=0.7769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcfe617293d5413ba82c573816697dfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 640\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:13, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.313700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.088900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=10: F1=0.7743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7f73d4cb2144219a66f3914a46f0e07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 960\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 00:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.307300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.098800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=15: F1=0.7658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48b4570b2e04c39974887f680026e33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 1280\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [240/240 00:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.299700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.111000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=20: F1=0.7818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "974c74b295394ea09ec2a84b06bc8655"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 1600\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:30, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.345600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.121800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=25: F1=0.7753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f46edb28212e4544a1a223ed85b0c901"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 1920\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 00:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=30: F1=0.7844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76cb7d675c2648f4a5e397fa1a533bb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 2240\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='420' max='420' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [420/420 00:42, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.391000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=35: F1=0.7851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to the training dataset\n",
            "Applying column mapping to the evaluation dataset\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/32 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "963c57d8e8cf45bb80c4bd5b737b34d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num unique pairs = 2560\n",
            "  Batch size = 16\n",
            "  Num epochs = 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [480/480 00:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.382700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.149300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.000100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:451: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  opt_res = optimize.minimize(\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "***** Running evaluation *****\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_iterations=40: F1=0.7816\n",
            "\n",
            "==================================================\n",
            "최적 num_iterations: 35\n",
            "최고 F1 Score: 0.7851\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 46384 (\\N{HANGUL SYLLABLE DDA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 47480 (\\N{HANGUL SYLLABLE REUN}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 45733 (\\N{HANGUL SYLLABLE NEUNG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 52572 (\\N{HANGUL SYLLABLE COE}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 44050 (\\N{HANGUL SYLLABLE GABS}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 54633 (\\N{HANGUL SYLLABLE HAB}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 50689 (\\N{HANGUL SYLLABLE YEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:70: UserWarning: Glyph 50669 (\\N{HANGUL SYLLABLE YEOG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 46384 (\\N{HANGUL SYLLABLE DDA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 47480 (\\N{HANGUL SYLLABLE REUN}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 45733 (\\N{HANGUL SYLLABLE NEUNG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 52572 (\\N{HANGUL SYLLABLE COE}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 44050 (\\N{HANGUL SYLLABLE GABS}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 54633 (\\N{HANGUL SYLLABLE HAB}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 50689 (\\N{HANGUL SYLLABLE YEONG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/tmp/ipython-input-2722057952.py:71: UserWarning: Glyph 50669 (\\N{HANGUL SYLLABLE YEOG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig('fewshot_iterations_analysis.png', dpi=300, bbox_inches='tight')\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46384 (\\N{HANGUL SYLLABLE DDA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47480 (\\N{HANGUL SYLLABLE REUN}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45733 (\\N{HANGUL SYLLABLE NEUNG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 52572 (\\N{HANGUL SYLLABLE COE}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44050 (\\N{HANGUL SYLLABLE GABS}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44284 (\\N{HANGUL SYLLABLE GWA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54633 (\\N{HANGUL SYLLABLE HAB}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50689 (\\N{HANGUL SYLLABLE YEONG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 50669 (\\N{HANGUL SYLLABLE YEOG}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "그래프 저장 완료: fewshot_iterations_analysis.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 최적 num_iterations 특정 불가\n",
        "\n",
        "### 실험 결과\n",
        "- 테스트 범위: 5~40\n",
        "- 최고 성능: 35 (F1: 0.785)\n",
        "- 패턴: 불규칙한 등락\n",
        "\n",
        "### 한계\n",
        "   - 매 실행마다 쌍 생성이 랜덤\n",
        "   - 동일 설정도 결과 달라질 수 있음\n",
        "    - **높은 노이즈로 인해 최적값 특정 어려움**"
      ],
      "metadata": {
        "id": "xiYMIO2294h6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aKIHJpCQdAm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0893d6df-43f8-4967-9814-e691f9fbd17f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model.model_head # 분류기 훈련이 완료되면 파란색"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "p6rn8zgbCvSh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7NbUeSn-QSe"
      },
      "source": [
        "## **마스크드 언어 모델링** (MLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **사전 훈련된 (BERT)모델 계속 훈련하는 방법**"
      ],
      "metadata": {
        "id": "LZcU5jJGI-Gf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z35PD47AXXnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c687bc65-0127-43c2-8915-12f1067e3149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# 모델: klue/bert-base\n",
        "model_id = \"klue/bert-base\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgLardIvEFTG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "42a8ed77202247ac83231c7006cf4384",
            "e4a119bd729b4ef7b3975d6b34dc8d83",
            "8717628536cb4b9e9281df77ee12c3ee",
            "09d9ce040d24415bb54fe4389d0a9134",
            "6caf660452644ad5a68634ffba27a44e",
            "e3c92dd043a44875bc77f441fd459880",
            "4c432d82fc7a4ed393cec6973da0d736",
            "e8f1f9c7532c44338ef20853b6976dfb",
            "7d5c4b803f5f4f64b3c6da8aa3f2b2c2",
            "fb1e4378a137469b8ebc63d848f7bffa",
            "014524ea568a4d438cc213497ac57556",
            "3bcaf10ab3cb4185a20acb0de3aa3973",
            "209f8b87313f43e8ac4968a5cc7f9e77",
            "c1e170dc31914c13b66ae8b820f55931",
            "b8135e7ddaea4ffdab6ed39927f05d13",
            "eaff73e5da4646b3815be1034dfc57dc",
            "dafcfd3854d147a18038adcc31656b5b",
            "4809c0c460614358a47ba29aec793e92",
            "efbc85c42ef7424f89c66c189ad5403b",
            "9d103a60109d42e48e0a43df8f5d86f4",
            "6e119b5acfd44298872acef9a351c480",
            "bb8c71bf28f24fee938b1d7340bb8062"
          ]
        },
        "outputId": "021194eb-e6b1-42f2-de01-f875012ae1c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/8500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42a8ed77202247ac83231c7006cf4384"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bcaf10ab3cb4185a20acb0de3aa3973"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def preprocess_function(examples):\n",
        "   return tokenizer(examples[\"document\"], truncation=True)\n",
        "\n",
        "# 데이터를 토큰화합니다.\n",
        "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
        "tokenized_train = tokenized_train.remove_columns(\"label\")\n",
        "tokenized_test = test_data.map(preprocess_function, batched=True)\n",
        "tokenized_test = tokenized_test.remove_columns(\"label\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 마스킹 방법\n",
        "    - 토큰 마스킹 : 단어 마스킹보다는 비교적 빠른 수렴\n",
        "    - 전체 단어 마스킹 : 정료하지만 복잡하고 느리다\n",
        "- 토큰 마스킹\n",
        "    - 문장에 있는 토큰의 15%를 랜덤하게 마스킹함\n",
        "    - 단어의 일부분만 마스킹 될 수 있다."
      ],
      "metadata": {
        "id": "KAB9r_z2Jrlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7Yfg_2TECs_"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "# 토큰 마스킹\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqnA-ROy7ZRG"
      },
      "outputs": [],
      "source": [
        "# from transformers import DataCollatorForWholeWordMask\n",
        "\n",
        "# # 전체 단어 마스킹\n",
        "# data_collator = DataCollatorForWholeWordMask(\n",
        "#     tokenizer=tokenizer,\n",
        "#     mlm=True,\n",
        "#     mlm_probability=0.15\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OduApRY03iOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02db1a38-9e3c-4a45-b47a-a363ef665034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        }
      ],
      "source": [
        "# 훈련 매개변수\n",
        "training_args = TrainingArguments(\n",
        "   \"model\",\n",
        "   learning_rate=2e-5,\n",
        "   per_device_train_batch_size=16,\n",
        "   per_device_eval_batch_size=16,\n",
        "   num_train_epochs=1,\n",
        "   weight_decay=0.01,\n",
        "   save_strategy=\"epoch\",\n",
        "   report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer 객체 생성\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_test,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-cRB3QmEiXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "08b1b585-e46f-41b4-fd90-8bdc20e8dafc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='532' max='532' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [532/532 00:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.924100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        }
      ],
      "source": [
        "# 훈련 시간이 오래 걸림(T4 20분 이상)\n",
        "# 사전 훈련된 토크나이저를 저장합니다.\n",
        "tokenizer.save_pretrained(\"mlm\")\n",
        "\n",
        "# 모델을 훈련합니다.\n",
        "trainer.train()\n",
        "\n",
        "# 업데이트된 모델을 저장합니다.\n",
        "model.save_pretrained(\"mlm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Mask 예측 결과 확인: (원본 모델)**"
      ],
      "metadata": {
        "id": "2pEjuKdbP9W4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfxN1p8TOg2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12634944-9726-4a01-f3ef-a73eee22feff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> 스토리가 너무 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 있 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 워낙 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 별로 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 라서 시간 가는 줄 몰랐다.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 모델을 로드하고 예측을 만듭니다.\n",
        "mask_filler = pipeline(\"fill-mask\", model=\"klue/bert-base\")\n",
        "preds = mask_filler(\"스토리가 [MASK]라서 시간 가는 줄 몰랐다.\")\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Mask 예측 결과 확인: (업데이트된 모델)**\n",
        "\n",
        "- 영화리뷰 학습을 통해 도메인 특화 어휘와 평가 표현이 크게 개선\n",
        "- 문맥적 논리성과 문법적 완성도는 추가 개선이 필요"
      ],
      "metadata": {
        "id": "NAlFhW8hQEpL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DoWbmlGC0H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogk1hJ4zOlAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba8eb62-f6ec-4d3c-e7de-5c31f591ec43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> 스토리가 별로 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 너무 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 재미 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 최고 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 뛰어나 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 뭐 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 짜 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 좋 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 진짜 라서 시간 가는 줄 몰랐다.\n",
            ">>> 스토리가 남달 라서 시간 가는 줄 몰랐다.\n"
          ]
        }
      ],
      "source": [
        "# 모델을 로드하고 예측을 만듭니다.\n",
        "# 마스크 예측 결과 개수 지정 방법\n",
        "mask_filler = pipeline(\"fill-mask\", model=\"mlm\", top_k=10)\n",
        "preds = mask_filler(\"스토리가 [MASK]라서 시간 가는 줄 몰랐다.\")\n",
        "\n",
        "# 결과를 출력합니다.\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기대했던 것\n",
        "\n",
        "  \"스토리가 [재미있어서] 시간 가는 줄 몰랐다\"\n",
        "\n",
        "- 실제 결과  \n",
        "\n",
        "  \"스토리가 [재미] 라서 시간 가는 줄 몰랐다\"\n",
        "\n",
        "- 원인: \"재미있어서\"가 다음과 같이 토큰화됨\n",
        "\n",
        "  - 토큰들 = [\"재미\", \"있어서\"] 또는 [\"재미\", \"##있\", \"##어서\"]\n",
        "  - 모델은 첫 번째 토큰 \"재미\"만 예측"
      ],
      "metadata": {
        "id": "QCaENm4PDM17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds[:5]"
      ],
      "metadata": {
        "id": "hE2cRuWnSp9Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275ff5db-5f9a-4f2e-f517-593ddb5a6130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.3985593616962433,\n",
              "  'token': 5429,\n",
              "  'token_str': '별로',\n",
              "  'sequence': '스토리가 별로 라서 시간 가는 줄 몰랐다.'},\n",
              " {'score': 0.11836191266775131,\n",
              "  'token': 3760,\n",
              "  'token_str': '너무',\n",
              "  'sequence': '스토리가 너무 라서 시간 가는 줄 몰랐다.'},\n",
              " {'score': 0.028566410765051842,\n",
              "  'token': 4697,\n",
              "  'token_str': '재미',\n",
              "  'sequence': '스토리가 재미 라서 시간 가는 줄 몰랐다.'},\n",
              " {'score': 0.02480860985815525,\n",
              "  'token': 3841,\n",
              "  'token_str': '최고',\n",
              "  'sequence': '스토리가 최고 라서 시간 가는 줄 몰랐다.'},\n",
              " {'score': 0.01693551614880562,\n",
              "  'token': 7999,\n",
              "  'token_str': '뛰어나',\n",
              "  'sequence': '스토리가 뛰어나 라서 시간 가는 줄 몰랐다.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds)"
      ],
      "metadata": {
        "id": "2JousAx3S6Ay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8be3c3-7c8d-4e0a-df18-c5e8f0252098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "T-xAqdV0SrJM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sDqoG2NyeJO"
      },
      "source": [
        "## **개체명 인식**\n",
        "\n",
        "- **개체명 인식** (**NER** named-entity recognition)\n",
        "- 전체 문서를 분류하는 것이 아니라 **사람이나 위치 등이 포함된 개별 토큰이나 단어를 분류**함\n",
        "- 민감한 데이터가 있을 때 익명화하는 작업에 특별히 도움됨\n",
        "- 개별 단어를 분류하는 데 초점을 맞추려면 세분화된 구조를 고려하도록 데이터를 전처리해야 한다.\n",
        "- 분류 방식:\n",
        "    - **모델이 시퀀스에 있는 개별 토큰에 대해 예측**을 만든다\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGDvXU-ZzJ3J"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOQlMioIGY33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "d9acf2b4805c41ac88059d30f53749c9",
            "da345311359b4a7b9d0cfdab69f3ed69",
            "d8ee694608f64a3788bcf78e79953346",
            "3707924d03094a70a19cc81f03f64e24",
            "ef387d6f199a4f8ca9823e07cea50702",
            "51faf2feab584c77964ac369125ed0a4",
            "566055934a874ba3b6c8d9dc420977bd",
            "a2ed090f3dfe48dd839f2760b1b62265",
            "1ad02fd4a5564fc78992b5a43b8a5f43",
            "93288ee98b2c42bd8fe3f8f2d7f591f4",
            "6096042b55a44dcba42e467420fbdd99",
            "8617dcd3d2bf4658992e43ccc20d271e",
            "77388a9378cf4db2bca356ac25f456fd",
            "2b9a7f2146604e63b9aa8f62f6bd010e",
            "e71afdb42c034717a34430614da44f7a",
            "553b7ad5a4e943c2a88d87d5d30dc470",
            "8d41b112fc924d3592f763a1cf04c8ba",
            "ab7fe57715654236b92b9ee5c1c0f304",
            "07be7116c407426a958132eaa210a0b1",
            "d9ac159c8e3444dba1fd78c7287d434a",
            "6a1dfaaf8ae242b0bb36bc9e178d03a1",
            "270d609c75514abca4c9bebb5838b221",
            "f23811b1d1e44575908fd295e74acb21",
            "4e383d2ac7fa4ac5b7b65b77047c53af",
            "576040e561a348b89ba4224b31a8a751",
            "4366cc588d5b465888f80285899a8d13",
            "51c7b660aedf48e8a30f13c584a8c1a5",
            "d12c0423cedf44a1b89fdeedf1338acc",
            "33d1d62d0d2f441c8dc963ac7eee6ee1",
            "7052f92f460a4497995ade02448f545f",
            "eff84a27f80b45089f8b566ade1347e0",
            "8a2a2b61caf240158a7ae9645a041565",
            "719829a323274196a5e500e3d09d6cfc",
            "52df221b613041eabaca0183d1697dec",
            "9d62cb35768e41eaa185430ca7b583f4",
            "a644501e60de49c5be38dc907a4a758d",
            "cf9e98e0eea54ea9a7f81e88d96dbafa",
            "1def251cdceb4ec48e397ef2c384b208",
            "419b3c7886af41c0891728e3f5cff51d",
            "2013deebe78b4463821460a70f0622c4",
            "8b0c2621ff5643eba71d61dd1ab75bb7",
            "87784626f2d94b04ba611e66fd1a4774",
            "2dc73319d7db480e8999f3a96d20e0f5",
            "ea9f3f0a4aa947e6b88599ae0867caaa",
            "e9a36a7cae3f4370abd7ae7234507e21",
            "3b8aa118834c4f059a7285d3c7478c4d",
            "da0464086f6c4a5aa2f5d6ec529d62cb",
            "8b300e3c2044402bb723ad55b5d2be05",
            "a6278e9255384e42bb49e9f37ba53a30",
            "3726fa73a52a4e3688d06b7504a8cfeb",
            "45f9b22fb0d54d1dbc644bf8adfaf13a",
            "194cfe9befd04daaa8a9457388a51b2c",
            "8d1244607fe14d7aa56e06fdf869034c",
            "cf1c4c578c7941aa90f0d9dbe2750aab",
            "c189b60d4c994421872e9d3b1c33fa28"
          ]
        },
        "outputId": "0763f9e2-2cd0-428d-8e81-8c1889b3c9b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9acf2b4805c41ac88059d30f53749c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ner/train-00000-of-00001.parquet:   0%|          | 0.00/4.21M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8617dcd3d2bf4658992e43ccc20d271e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ner/validation-00000-of-00001.parquet:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f23811b1d1e44575908fd295e74acb21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/21008 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52df221b613041eabaca0183d1697dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9a36a7cae3f4370abd7ae7234507e21"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "dataset = load_dataset(\"klue\", \"ner\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "S-97JmZlWNse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9906fba3-134f-4963-d482-6d05ff1102c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence', 'tokens', 'ner_tags'],\n",
              "        num_rows: 21008\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence', 'tokens', 'ner_tags'],\n",
              "        num_rows: 5000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOc5J7YgIPl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1405c2fb-3add-42bc-f9ca-664ac863ae82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence': '마지막 영화 <1분:TI>이 이영화에 대한 나의 인식을 바꿨다.',\n",
              " 'tokens': ['마',\n",
              "  '지',\n",
              "  '막',\n",
              "  ' ',\n",
              "  '영',\n",
              "  '화',\n",
              "  ' ',\n",
              "  '1',\n",
              "  '분',\n",
              "  '이',\n",
              "  ' ',\n",
              "  '이',\n",
              "  '영',\n",
              "  '화',\n",
              "  '에',\n",
              "  ' ',\n",
              "  '대',\n",
              "  '한',\n",
              "  ' ',\n",
              "  '나',\n",
              "  '의',\n",
              "  ' ',\n",
              "  '인',\n",
              "  '식',\n",
              "  '을',\n",
              "  ' ',\n",
              "  '바',\n",
              "  '꿨',\n",
              "  '다',\n",
              "  '.'],\n",
              " 'ner_tags': [12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12,\n",
              "  12]}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "example = dataset[\"train\"][848]\n",
        "example"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **ner_tags** : 개체명 태그\n",
        "    - 사람(PER),조직(ORG), 위치(LOC), 기타매체(MISC), 개체아님(O)\n",
        "    - 개체마다 B(시작),I(중간)"
      ],
      "metadata": {
        "id": "HDW_GZI3WuFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPNSdADeAWD"
      },
      "outputs": [],
      "source": [
        "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "label2id = {l:i for i,l in enumerate(label_list)}\n",
        "id2label = {i:l for l,i in label2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtRCaz15AyjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6297b67-3540-454e-e3b0-cb255154f95b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# 토크나이저를 로드합니다.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "model_id = \"klue/bert-base\"\n",
        "# 모델을 로드합니다.\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(id2label),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토크나이저가 샘플을 처리하는 방법 확인"
      ],
      "metadata": {
        "id": "o-7q2RPWZR_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example[\"tokens\"]"
      ],
      "metadata": {
        "id": "8izl7YMfZwZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7d7445-664f-41cc-8eef-9e7edf970341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['마',\n",
              " '지',\n",
              " '막',\n",
              " ' ',\n",
              " '영',\n",
              " '화',\n",
              " ' ',\n",
              " '1',\n",
              " '분',\n",
              " '이',\n",
              " ' ',\n",
              " '이',\n",
              " '영',\n",
              " '화',\n",
              " '에',\n",
              " ' ',\n",
              " '대',\n",
              " '한',\n",
              " ' ',\n",
              " '나',\n",
              " '의',\n",
              " ' ',\n",
              " '인',\n",
              " '식',\n",
              " '을',\n",
              " ' ',\n",
              " '바',\n",
              " '꿨',\n",
              " '다',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOrlt03kIt_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edae03ce-2195-4ec0-d5ba-adafea8809ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " '마',\n",
              " '지',\n",
              " '막',\n",
              " '영',\n",
              " '화',\n",
              " '1',\n",
              " '분',\n",
              " '이',\n",
              " '이',\n",
              " '영',\n",
              " '화',\n",
              " '에',\n",
              " '대',\n",
              " '한',\n",
              " '나',\n",
              " '의',\n",
              " '인',\n",
              " '식',\n",
              " '을',\n",
              " '바',\n",
              " '꿨',\n",
              " '다',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# 개별 토큰을 부분 토큰으로 나눕니다.\n",
        "token_ids = tokenizer(example[\"tokens\"], is_split_into_words=True)[\"input_ids\"]\n",
        "sub_tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
        "sub_tokens\n",
        "\n",
        "# is_split_into_words=True: 토크나이저가 단어 리스트로 처리하도록 지시 (NER 라벨 정렬에 유리)\n",
        "# [\"input_ids\"]: 토큰화된 결과 중 정수 ID 시퀀스만 꺼냄"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- align_labels\n",
        "    - 입력을 토큰으로 나누고, 토큰을 업데이트된 레이블로 정렬하는 함수"
      ],
      "metadata": {
        "id": "BXkFFVN6a-T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s5A3mzj6TXf"
      },
      "outputs": [],
      "source": [
        "def align_labels(examples):\n",
        "    # 1. 토큰들을 문장으로 재구성\n",
        "    reconstructed_texts = []\n",
        "    for tokens in examples[\"tokens\"]:\n",
        "        text = ''.join(tokens)\n",
        "        reconstructed_texts.append(text)\n",
        "\n",
        "    # 2. 재구성된 문장으로 토큰화\n",
        "    tokenized_inputs = tokenizer(\n",
        "        reconstructed_texts,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        return_offsets_mapping=True  # 문자 위치 정보 포함\n",
        "    )\n",
        "\n",
        "    # 3. 라벨 정렬\n",
        "    aligned_labels = []\n",
        "\n",
        "    for batch_idx, (original_tokens, original_labels, offsets) in enumerate(\n",
        "        zip(examples[\"tokens\"], examples[\"ner_tags\"], tokenized_inputs[\"offset_mapping\"])\n",
        "    ):\n",
        "\n",
        "        # 원본 토큰의 문자 위치 계산\n",
        "        char_to_original_token = {}\n",
        "        char_pos = 0\n",
        "\n",
        "        for token_idx, token in enumerate(original_tokens):\n",
        "            for _ in range(len(token)):\n",
        "                char_to_original_token[char_pos] = token_idx\n",
        "                char_pos += 1\n",
        "\n",
        "        # 서브토큰별 라벨 할당\n",
        "        labels = []\n",
        "        for start, end in offsets:\n",
        "            if start == end == 0:  # [CLS], [SEP] 등 특수 토큰\n",
        "                labels.append(-100)\n",
        "            else:\n",
        "                # 해당 위치의 원본 토큰 인덱스 찾기\n",
        "                if start < len(char_to_original_token):\n",
        "                    original_token_idx = char_to_original_token[start]\n",
        "                    labels.append(original_labels[original_token_idx])\n",
        "                else:\n",
        "                    labels.append(-100)\n",
        "\n",
        "        aligned_labels.append(labels)\n",
        "\n",
        "    # offset_mapping 제거 (학습에 불필요)\n",
        "    tokenized_inputs.pop(\"offset_mapping\")\n",
        "    tokenized_inputs[\"labels\"] = aligned_labels\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIWOMzE-AhTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515,
          "referenced_widgets": [
            "ce729c330fc349bb95c91bd084fccb4e",
            "cf1c1a8732af4e79b2d04f283448e8af",
            "eac6571b3b824e95800498915e15a104",
            "7e0ccd2e41b24e9e9807e1cf16359dae",
            "316675656ccd40149f2c534bf5f7eb35",
            "c7e0624e03434b3aa4cab239fdfeafba",
            "900cdde144434a60ade6da00d573700c",
            "b856917c566d4e588e608b15e7a4bc26",
            "3ec4e98dc5cb477d92982c2d5a3a445a",
            "1d519526caa94902b32ea9243e002369",
            "2d067a57b8e34bcc9bc7771fba461304",
            "95c540e88e464b5b80321af153ddfa56",
            "4fde31f3d2cd4b5898dcf13e2c4cf7f3",
            "865a7dbe50b649e5b27f25d964405e1e",
            "220690790c9d4034b360122547c18659",
            "49c4e32702524ef38bde05597f7b1426",
            "9d2db83aca5141038e805ec7056d8f77",
            "fd9919c750d240dc9c52623ae4bc0b52",
            "f9c631bd8aa648a78a8cf210845aa835",
            "02a63988af9e453db522eb88cdead3a9",
            "a8f3c5e6cb4c48d3bcd1fb677ee6ce98",
            "5c46db37c9944fd0b492c3ac35006fea"
          ]
        },
        "outputId": "69124cc4-b551-4633-ae55-a03b9a561527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터셋 재전처리 중...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/21008 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce729c330fc349bb95c91bd084fccb4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95c540e88e464b5b80321af153ddfa56"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 샘플 848 재전처리 결과 ===\n",
            "원본 문장: 마지막 영화 <1분:TI>이 이영화에 대한 나의 인식을 바꿨다.\n",
            "재구성된 문장: 마지막 영화 1분이 이영화에 대한 나의 인식을 바꿨다.\n",
            "\n",
            "토큰 vs 라벨:\n",
            "  [CLS]           -> IGNORE\n",
            "  마지막             -> O\n",
            "  영화              -> O\n",
            "  1               -> B-TI\n",
            "  ##분             -> I-TI\n",
            "  ##이             -> O\n",
            "  이영              -> O\n",
            "  ##화             -> O\n",
            "  ##에             -> O\n",
            "  대한              -> O\n",
            "  나               -> O\n",
            "  ##의             -> O\n",
            "  인식              -> O\n",
            "  ##을             -> O\n",
            "  바꿨              -> O\n",
            "  ##다             -> O\n",
            "  .               -> O\n",
            "  [SEP]           -> IGNORE\n"
          ]
        }
      ],
      "source": [
        "print(\"데이터셋 재전처리 중...\")\n",
        "tokenized_dataset = dataset.map(align_labels, batched=True)\n",
        "\n",
        "# 결과 확인\n",
        "sample_idx = 848\n",
        "print(f\"\\n=== 샘플 {sample_idx} 재전처리 결과 ===\")\n",
        "original_sample = dataset[\"train\"][sample_idx]\n",
        "processed_sample = tokenized_dataset[\"train\"][sample_idx]\n",
        "\n",
        "print(f\"원본 문장: {original_sample['sentence']}\")\n",
        "print(f\"재구성된 문장: {''.join(original_sample['tokens'])}\")\n",
        "\n",
        "# 토큰화 결과 확인\n",
        "tokens = tokenizer.convert_ids_to_tokens(processed_sample['input_ids'])\n",
        "labels = processed_sample['labels']\n",
        "\n",
        "print(f\"\\n토큰 vs 라벨:\")\n",
        "for token, label in zip(tokens, labels):\n",
        "    label_name = id2label[label] if label != -100 else \"IGNORE\"\n",
        "    print(f\"  {token:15} -> {label_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE1XbzOM2QWn",
        "outputId": "58857c0c-60f5-4c78-caad-42d65a6a9fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from seqeval) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA9nE7E6g97p"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "# seqeval을 로드합니다.\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "# 평가 함수\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=2)\n",
        "\n",
        "    true_predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for token_prediction, token_label in zip(prediction, label):\n",
        "            if token_label != -100:\n",
        "                true_predictions.append([id2label[token_prediction]])\n",
        "                true_labels.append([id2label[token_label]])\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\"f1\": results[\"overall_f1\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0S4ZajdCaJl"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# 토큰 분류 DataCollator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S76kRYZtBr5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "e4d9f0af-87a4-4718-d5af-308e74ec68c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2626' max='2626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2626/2626 02:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.065100</td>\n",
              "      <td>0.069436</td>\n",
              "      <td>0.942620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.038200</td>\n",
              "      <td>0.072277</td>\n",
              "      <td>0.944241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/internal/well_known_types.py:178: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  self.FromDatetime(datetime.datetime.utcnow())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2626, training_loss=0.056652990262742633, metrics={'train_runtime': 151.6937, 'train_samples_per_second': 276.979, 'train_steps_per_second': 17.311, 'total_flos': 1279297320963360.0, 'train_loss': 0.056652990262742633, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "# 훈련 설정\n",
        "training_args = TrainingArguments(\n",
        "    \"model_ner_ko\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,  # 에폭 수 증가\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    logging_steps=100\n",
        ")\n",
        "\n",
        "# 트레이너 생성\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds5osPr9T0pq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "00a811b3-54cb-4788-da8e-334ea446a8bc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [313/313 00:05]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.0722770169377327,\n",
              " 'eval_f1': 0.9442410802436321,\n",
              " 'eval_runtime': 11.1669,\n",
              " 'eval_samples_per_second': 447.754,\n",
              " 'eval_steps_per_second': 28.029,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "# 테스트 데이터에서 모델을 평가합니다.\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **모델 저장 및 추론 수행**"
      ],
      "metadata": {
        "id": "n-USVae8dtT1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0PAXyzT-N45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a35171b-6353-4641-cdc0-7635a9791ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏷️ 엔티티 분류 결과:\n",
            "------------------------------\n",
            "DT: 2024년 3월 15일, 조선시대\n",
            "LC: 서울대학교, 부산 해운대 벡스코\n",
            "OG: 삼성전자, 구글코리아\n",
            "PS: 김철수, 이순신, 박지영\n",
            "QT: 500명, 50억원\n",
            "TI: 오후 3시\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from collections import defaultdict\n",
        "\n",
        "# 미세 튜닝된 모델을 저장합니다.\n",
        "trainer.save_model(\"ner_model-ko\")\n",
        "\n",
        "\n",
        "\n",
        "# 미세 튜닝된 모델로 추론을 수행합니다.\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\",\n",
        "    model=\"ner_model-ko\",\n",
        "    aggregation_strategy=\"simple\"\n",
        ")\n",
        "text = \"\"\"\n",
        "2024년 3월 15일 오후 3시에 삼성전자 임직원 500명이 서울대학교에서 열린\n",
        "'인공지능과 미래사회' 세미나에 참석했다. 이 행사에서 김철수 교수는\n",
        "조선시대 이순신 장군의 리더십을 현대 경영학에 접목한 연구를 발표했으며,\n",
        "구글코리아 박지영 대표는 50억원 규모의 AI 투자 계획을 발표했다.\n",
        "행사장인 부산 해운대 벡스코에서는 삼겹살과 김치를 포함한 한식 뷔페가\n",
        "제공되었고, 참가자들은 갤럭시 스마트폰으로 QR코드를 스캔하여\n",
        "디지털 명함을 교환했다.\n",
        "\"\"\"\n",
        "result = token_classifier(text)\n",
        "# 유형별로 분류\n",
        "entities_by_type = defaultdict(list)\n",
        "for entity in result:\n",
        "    entities_by_type[entity['entity_group']].append(entity['word'])\n",
        "\n",
        "print(\"🏷️ 엔티티 분류 결과:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for entity_type, words in sorted(entities_by_type.items()):\n",
        "    print(f\"{entity_type}: {', '.join(words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "klue_entities = {\n",
        "    # 인물 관련\n",
        "    'PS': 'Person - 인명 (박지성, 김철수, 이순신 등)',\n",
        "    \n",
        "    # 장소 관련  \n",
        "    'LC': 'Location - 지명 (서울, 부산, 맨체스터 등)',\n",
        "    \n",
        "    # 기관 관련\n",
        "    'OG': 'Organization - 기관명 (삼성전자, 서울대학교, 맨체스터 유나이티드 등)',\n",
        "    \n",
        "    # 날짜/시간\n",
        "    'DT': 'Date/Time - 날짜/시간 (2024년, 오늘, 3시 등)',\n",
        "    \n",
        "    # 수량\n",
        "    'QT': 'Quantity - 수량 (100개, 50%, 3명 등)',\n",
        "    \n",
        "    # 기타 고유명사\n",
        "    'CV': 'Civilization - 문명/문화 (조선시대, 르네상스 등)',\n",
        "    'AM': 'Animal - 동물명',\n",
        "    'PT': 'Plant - 식물명',\n",
        "    'MT': 'Material - 물질명',\n",
        "    'TI': 'Title - 작품명/타이틀',\n",
        "    'EV': 'Event - 사건명',\n",
        "    'AF': 'Artifact - 인공물',\n",
        "    'TR': 'Term - 용어',\n",
        "    'FD': 'Food - 음식명',\n",
        "}"
      ],
      "metadata": {
        "id": "go_6KMlDNxBe"
      }
    }
  ]
}